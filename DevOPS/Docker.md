
## Что такое Docker?

Docker - это платформа контейнеризации с открытым исходным кодом, с помощью которой можно автоматизировать создание приложений, управление и доставку.
Платформа позволяет быстрее тестировать и выкладывать приложение, запускать на одной машине требуемое количество контейнеров.

Благодаря контейнеризации и Docker разработчикам больше не приходится думать о том, в какой среде будет функционировать приложение. Достаточно упаковать приложение со всеми зависимостями в контейнер, чтобы запускать в любых системах.
Контейнеры позволяют отделить приложение от инфраструктуры, т.к. они не зависят от инфраструктуры.


## Особенности контейнеров

* **Сравнительно короткий жизненный цикл.** Любой контейнер можно остановить, перезапустить, удалить. Данные при этом внутри контейнера тоже пропадут. Так выработалось правило: **Не хранить важные данные в контейнере (Stateless)**.
* **Объём контейнеров измеряется в мегабайтах**, поскольку в них упаковываются лишь те процессы и зависимости ОС, которые необходимы для выполнения кода.
* **Один контейнер соответствует одному запущенному процессу.** Отключение отдельного контейнера никак не помешает работе всего приложения в целом.
* **Контейнеризация обеспечивает надёжную изоляцию процессов и повышает уровень безопастности**, т.к. приложение внутри контейнера не имеет доступ к внешней ОС.
* **Благодаря контейнерам можно автоматизировать развёртывание приложений на разных хостах.**
* **Проще перейти с монолита на микросервисную архитектуру.**
* **С точки зрения эффективности контейнеры котируются выше виртуальных машин**. На одинаковом оборудовании можно запустить большее количество контейнеров, тогда как виртуальных машин будет в разы меньше. Это важно при использовании облачной инфраструктуры — потребуется меньше ресурсов.


## Преимущества контейнеров

* **Гибкость  и адаптивность**. Благодаря Docker можно легко запускать контейнер в облачной инфраструктуре и на любом локальном устройстве. Можно создать базовые шаблоны контейнеров и использовать повторно бесконечное число раз. Бесшовная переносимость и простота развертывания — важные преимущества этой технологии.

* **Меньше ошибок и несовпадений окружений**: В контейнерах Docker содержится всё, что требуется для запуска приложения, поэтому перенос приложений из одной среды в другую не вызывает затруднений. Исчезает проблема, когда у разработчиков всё функционирует как надо, а на боевом сервере — нет.

* **Скорость развертывания**: Так как настраивать окружение для разработки, тестирования и боевого режима больше не нужно, время развертывания сокращается в несколько раз.

* **Рост универсальности**: Docker позволяет использовать любые языки программирования и стек технологий на сервере, избавляя от проблемы несовместимости разных библиотек и технологий.

* **Комьюнити и поддержка**: Существует огромная библиотека контейнеров с открытым исходным кодом. Можно использовать нужный Docker образ для конкретной задачи.

* **Непрерывность работы**: Можно выстроить процесс обновления так, чтобы обновления контейнеров не влияло на работоспособность системы.

* **Упрощения администрирования**: С помощью Docker легче переносить контейнер с одного хоста на другой, запустить сразу несколько образов,  обновить группы контейнеров и откатиться к старой версии. 

* **Повышение уровня безопасности**: Контейнеры в Docker частично изолированы друг от друга на уровне процессов и ОС, поэтому запуск большого количества контейнеров на одной машине не несет рисков.

* **Экономическая эффективность**: Контейнеры легковесны и производительны, а благодаря использованию Docker можно эффективнее управлять имеющимися ресурсами и сократить расходы компании.

* **Современный подход**: Отказ от монолитной архитектуры в пользу микросервисной позволяет более гибко развивать продукт, добавлять в него новые функции.


## Как устроен Docker образ

Базовый образ - главный элемент контейнеризации в Docker. В нём содержаться процессы и зависимости, необходимые для нормальной работы приложения. 
Обычно скачиваются уже готовые Docker образы с Docker Hub (их более 100 000).

На базовый Docker образ накладываются, один за другим, доступные только для чтения слои, которые образуются после любых изменений в образе. 
Каждый новый слой - актуальная версия образа.
Получается финальный образ - это объединение всех слоёв в 1.
Такое решение экономит пространство диска и сокращает время сборки контейнера.\
![[Pasted image 20240623142331.png]]

Если образ — это набор доступных только для чтения слоев, то контейнер представляет собой тот же образ, но с еще одним слоем сверху — с возможностью записи. Информация записывается в контейнер, а когда он уничтожается, верхний слой и содержащиеся в нем данные пропадают. В случае необходимости создается новый (чистый) контейнер из старого образа.

В любом образе Docker хранится Docker manifest. Это JSON-файл, содержащий информацию об образе: ссылки на каждый существующий слой, данные об их размере, хеш, а также сведения о платформе, на которой он будет работать.



## Архитектура и компоненты Docker

**Компоненты рабочего процесса**: 
* **Сервер, или демон Docker.** Выполняется в хост-системе и управляет всеми запущенными контейнерами.

* **Контейнер Docker.** Автономная виртуальная система, содержащая выполняющийся процесс, все файлы, зависимости, адресное пространство процесса и сетевые порты, необходимые приложению. Так как каждый контейнер имеет свое пространство портов, следует организовать их отображение в фактические порты на уровне Docker. Мы еще вернемся к этому вопросу.

 * **Клиент Docker.** Пользовательский интерфейс, или интерфейс командной строки.
 
 * **Образы Docker.** Шаблонные файлы, доступные только для чтения, с контейнером Docker. Их можно перемещать и передавать. В отличие от виртуальных машин, эти файлы можно хранить в системе управления версиями. Более того, можно воспользоваться командой `docker diff`, чтобы увидеть различия между двумя образами. Каждый образ состоит из нескольких уровней, или слоев, которые могут совместно использоваться несколькими образами. Допустим, вы обновили существующее приложение. В результате в существующий образ будет добавлен дополнительный уровень. Благодаря такой организации можно распространять и развертывать только новые уровни, упрощая и ускоряя процесс.
 
 * **Реестр Docker**: Репозиторий для хранения и распространения образов контейнеров Docker. Примером широко известного реестра может служить Docker Hub (во многом похож на GitHub), куда можно помещать и откуда можно извлекать образы. Внутри своей организации вы можете организовать свой реестр.
 
 * **Файл Dockerfile**: Это очень простой текстовый файл, содержащий команды, которые выполняют сборку образов Docker. Посредством этих команд можно устанавливать дополнительные программные компоненты, настраивать переменные окружения, рабочие каталоги и точку входа `ENTRYPOINT`, а также добавлять новый код.
 
 * **Docker Machine**: Docker Machine позволяет развертывать узлы Docker на локальной машине или внутри общедоступного либо частного облака, включая облачные системы таких поставщиков, как Amazon и Microsoft Azure. Также он обеспечивает управление узлами посредством команд `start`, `stop`, `inspect` и других.
 
* **Компоновщик Docker Compose**: Приложения часто состоят из множества компонентов, и соответственно они будут выполняться в нескольких контейнерах. В состав Docker входит инструмент Compose, с помощью которого можно легко запустить приложение в нескольких контейнерах. Вы можете определить окружение для приложения в общем файле Dockerfile и определить перечень служб в файле `docker-compose.yml`, после чего Docker автоматически будет создавать и запускать необходимые контейнеры, как определено в этих файлах. Инструмент Compose так же, как Docker Machine, имеет свой набор команд для управления службами приложения.


## Основные команды Docker

* **sudo docker search `package_name`**. Используется для поиска образов доступных в реестре Docker. Также можно добавить ключ `--filter`. Пример:

```bash
sudo docker search --filter stars=50 django
```

* **sudo docker pull `image:tag`**. Загружает указанный образ из реестра Docker на локальный компьютер. Если `tag` не указан, то команда подставит тег `latest` и загрузит только последнюю версию образа. Пример:	

```bash
sudo docker pull django:latest
```

*  **docker images `options`**. Возвращает список образцов верхнего уровня, доступных на локальном компьютере. Пример: (выведет список всех образцов верхнего уровня, включающих название репозитория, тэг, дату создания и виртуальный размер). 

```bash
sudo docker images -a 
```

* **docker rmi `options` `image [image, image...]`**.  Удаляет  указанный образ (образы) на локальном компьютере. Пример:

```bash
sudo rmi django
```

* **docker run `options` `image:tag` `[command, args]`**. Запуск образа. Данная команда разворачивает контейнер в его собственной файловой системе, имеющей свой набор портов и IP-адрес. Кроме названия образа, команде `run` можно также передать дополнительные ключи и аргументы. Вот наиболее часто используемые из них:
	  `--interactive`: переключает команду в интерактивный режим и открывает STDIN;
	 `--tty`: создает псевдотерминал TTY.
  Команда `docker run` поддерживает множество других ключей, например для запуска процесса в фоновом режиме `-d`, когда контейнер запускается без поддержки командной строки. Также можно переопределить являющиеся частью запускаемого образа команды по умолчанию. Дополнительно можно задать ограничения на объем памяти и количество доступных процессоров. Пример: 

Запуск образа Ubuntu
```bash
sudo docker run ubuntu:latest
```
Теперь запустим этот образ на локальном компьютере с ключами:
`--interactive` и `--tty`.

Дополнительно потребуем запустить процесс командной оболочки:
```bash
sudo docker run --interactive --tty ubuntu sh
```

Сейчас на локальном компе выполняется контейнер Ubuntu. При помощи этой команды теперь возможно выполнять любые команды внутри контейнера Ubuntu.

* **docker ps `options`**. Выводит список всех контейнеров, запущенный в данный момент. Пример: 
```bash
sudo docker ps
```
Добавив ключ `-a` увидим также и не запущенные контейнеры.

* **docker restart `[options]` `container`**. Перезапуск указанного контейнера. Пример перезапуска (указав идентификатор)
```bash
sudo docker restart 7736ab85aeb4
```
Введя **docker ps** можно увидеть, что теперь контейнер активный.

* **docker attach `[options]` `container`**. Команда позволяет передать указанный активный контейнер под интерактивное управление или увидеть его стандартный вывод. Пример:
```bash
sudo docker attach 7736ab85aeb4
```
Важно отметить, что мы всегда будем получать приглашение к вводу после каждого перезапуска контейнера. Это поведение по умолчанию нельзя изменить, потому что мы определили его, собрав контейнер с ключом `--interactive` в команде `run`. Конечно, мы можем запустить тот же образ `Ubuntu` с другими ключами и параметрами. В этом заключается особая прелесть Docker.

* **docker rm `[options]` `container`**.  Удаляет указанные контейнеры. Попробуем для примера удалить контейнер `ubuntu`. Перед удалением контейнер нужно остановить или передать команде `rm` ключ `–f` (force – принудительно), действие которого заключается в отправке сигнала `SIGKILL` процессу, выполняющемуся в контейнере:
  **docker stop `[options]` `container`**. Пример:
```bash
sudo docker stop 7736ab85aeb4
```
Команда `stop` сначала посылает сигнал `SIGTERM`, а затем, выждав некоторое время, сигнал `SIGKILL`. Период ожидания можно изменить, передав ключ –t с числом секунд. Эта возможность может очень пригодиться в случаях, когда требуется, чтобы процесс в контейнере успел завершить обработку запроса (например, запроса HTTP).

Также можно воспользоваться командой `docker kill`, которая немедленно посылает сигнал `SIGKILL`, но в этом случае процесс в контейнере не получит возможности завершиться обычным путем. Однако эта команда имеет ключ, позволяющий послать процессу в контейнере другой сигнал, отличный от `SIGKILL`.

Пример (docker rm):
```bash
sudo docker rm 7736ab85aeb4
```

* **sudo docker exec `[options]` `container` `command` `[arg...]`**. Команда позволяет удалённо выполнить другую команду в уже запущенном контейнере.
Пример (запустит ls -a внутри контейнера ubuntu):
```bash
sudo docker exec 7736ab85aeb4 ls -a
```

* **docker rename `container` `new_name`**. Позволяет дать контейнерам осмысленные имена, которые проще запомнить и классифицировать. Пример:
```bash
sudo docker rename ee7d9365ce54 ubuntu_main
```

* **docker start/stop `container`**. Запускает/останавливает остановленный/запущенный контейнер. Пример:
```bash
sudo docker stop ubuntu_main
```

Также можно перезапустить контейнер не отключая его.
```bash
sudo docker stop ubuntu_main && sudo docker start ubuntu_main
```

* **docker cp `[options]` container:src_path dest_path**. Позволяет копировать файлы между контейнером и машиной, на которой тот выполняется. \
  Пример (1 - копирует файл myfile.txt из ubuntu_main в корень, 2-наоборот):
```bash
sudo docker cp ubuntu_main:/myfile.txt .
_____
sudo docker cp myfile.txt ubuntu_main:/var
```

* **docker pause/unpause `container`**. Приостанавливает/возобновляет все процессы в указанных контейнерах. В Linux она использует механизм управления группами процессов. Пример:
```bash
sudo docker pause container
```

* **docker create `[options]` `image` `[command] [arg...]`**. Создает новый уровень контейнера, доступный для записи, поверх указанного образа и подготавливает его для выполнения указанной команды. Пример:
```bash
sudo docker create -t -i fedora bash
```
* **docker commit `[options]` `container` `[repository:tag]`**. Команда `docker commit` является простой, но очень важной. Она позволяет создать новый образ со всеми изменениями, выполненными в контейнере. Если, выполнив какие-то изменения в контейнере, вы решите передать его кому-то, например группе разработки или тестирования, в виде образа, то сможете создать такой образ из запущенного контейнера.
* **docker diff**. Выводит изменения в файлах и каталогах в файловой системе контейнера


## Что такое Docker Images?

**Docker Iimage** - это исполняемый пакет ПО, который включает в себя все необходимые для запуска приложения. Этот образ информирует о том, как контейнер должен создавать экземпляр, определяя, какие программные компоненты будут работать и как.

**Docker Container** - это виртуальная среда, которая объединяет код приложения со всеми зависимостями, необходимыми для запуска приложения. Приложение работает быстро и надежно из одной вычислительной среды в другую.

### Использование Docker Images

- Мы можем легко и эффективно запускать контейнеры с помощью образов.

- Весь код, настройки конфигурации, переменные среды, библиотеки и время выполнения включены в образ Docker.

- Образы Docker не зависят от платформы.

- Слои являются строительными блоками.

- При использовании команды сборки у пользователя есть возможность полностью начать с нуля или использовать существующий образ.

### Разница между Docker Image и Docker Container

| Образ Docker                                                                    | Контейнер Docker                                                                   |
| ------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- |
| Образ Docker является исходным кодом контейнера Docker.                         | Контейнер Docker является экземпляром образа Docker.                               |
| Dockerfile является обязательным условием для образа Docker.                    | Образ Docker является предварительным условием для контейнера Docker.              |
| Образы Docker могут быть переданы пользователям с помощью реестра Docker.       | Контейнеры Docker не могут быть разделены между пользователями.                    |
| Чтобы внести изменения в образ Docker, нам нужно внести изменения в Dockerfile. | Мы можем напрямую взаимодействовать с контейнером и вносить необходимые изменения. |

### Структура Образа Docker

Слои программного обеспечения, которые составляют образ Docker, облегчают настройку зависимостей, необходимых для выполнения контейнера.

- **Базовый образ**: Базовый образ будет отправной точкой для большинства Dockerfiles, и его можно сделать с нуля.

- **Родительский образ**: Родительский образ - это образ, на котором основано наш образ. Мы можем ссылаться на родительский образ в Dockerfile с помощью команды `FROM`, и каждое объявление после этого влияет на родительский образ.

- **Слои**: Образы Docker имеют множество слоев. Чтобы создать последовательность промежуточных образов, каждый слой создается поверх предыдущего.

- **Реестр Docker**: Это система для хранения и распространения образов Docker с определенными именами. Может быть несколько версий одного и того же образа, каждая со своим собственным набором тегов. Реестр Docker разделен на репозитории Docker, в каждом из которых хранятся все модификации образа.

Перед тем, как создать образ Docker нам необходимо написать Dockerfile. 

![](https://ucarecdn.com/4de69e4c-d7f5-4af9-bb19-11d3e225ffc6/)

Docker может автоматически создавать образы читая инструкции из Dockerfile используя DSL (Domain Specific Language).

Файл Dockerfile представляет из себя текстовый документ содержащий все команды для сборки образа.

С помощью команды `docker build`, пользователи могут производить автоматизированную сборку, которая выполняет последовательность инструкций в командной строке.
 
## Введение в Docker Compose

Docker Compose — это инструментальное средство, входящее в состав Docker. Оно предназначено для решения задач, связанных с развёртыванием проектов.  
  
Изучая основы Docker, вы могли столкнуться с созданием простейших приложений, работающих автономно, не зависящих, например, от внешних источников данных или от неких сервисов. На практике же подобные приложения — редкость. Реальные проекты обычно включают в себя целый набор совместно работающих приложений.

Как узнать, нужно ли вам, при развёртывании некоего проекта, воспользоваться Docker Compose? На самом деле — очень просто. Если для обеспечения функционирования этого проекта используется несколько сервисов, то Docker Compose может вам пригодиться. Например, в ситуации, когда создают веб-сайт, которому, для выполнения аутентификации пользователей, нужно подключиться к базе данных. Подобный проект может состоять из двух сервисов — того, что обеспечивает работу сайта, и того, который отвечает за поддержку базы данных.  
  
**Технология Docker Compose, если описывать её упрощённо, позволяет, с помощью одной команды, запускать множество сервисов.**

### Разница между Docker и Docker Compose

Docker применяется для управления отдельными контейнерами (сервисами), из которых состоит приложение.  
  
Docker Compose используется для одновременного управления несколькими контейнерами, входящими в состав приложения. Этот инструмент предлагает те же возможности, что и Docker, но позволяет работать с более сложными приложениями.

![](https://ucarecdn.com/403d1d9b-735d-47ae-89a7-28a5d4a6e256/)

## Docker Compose на примере Django, Postgresql и Memcached

В этом разделе разберемся с тем, что такое Docker Compose и как он работает на реальном небольшом проекте — положим Django и PostgreSQL в контейнеры, так чтобы они работали как одно целое. Для сборки кластера контейнеров используется `docker-compose.yml`.

**Docker-compose.yml** — конфигурационный файл в YAML-формате, описывающий логику запуска и взаимодействия контейнеров между собой и внешним миром. В сущности инструкции заложенные в `docker-compose.yml` по логике работы идентичны ключам команды `docker run`.

Для запуска контейнеров через `docker-compose` используются следующие команды:

- `docker-compose build`: собрать проект

- `docker-compose up -d`: запустить проект

- `docker-compose down`: остановить проект

- `docker-compose logs -f [service name]`: посмотреть логи сервиса

- `docker-compose ps`: вывести список контейнеров

- `docker-compose exec [service name] [command]`: выполнить команду в контейнере

- `docker-compose images`: вывести список образов


### Подготовка проекта к Docker Compose

Первым делом нам необходимо удалить команды из Dockerfile которые открывают доступ к порту и выполняют команды запуска:

```dockerfile
EXPOSE 8000

CMD ["python", "manage.py", "runserver", "0.0.0.0:8000"]
```

Далее вынесем некоторые настройки в отдельный файл, в основном, что делает `python-dotenv`**,** это считывает пары ключ-значение из файла `.env` и устанавливает их как переменные среды для последующего извлечения.

Для этого необходимо обновить список зависимостей `requirements.txt`, добавив туда следующую строку:

```
python-dotenv==1.0.0
```

  
И отредактировать файл настроек `settings.py`, добавить в самое начала файла следующий код:

```python
from dotenv import load_dotenv
import os
load_dotenv()
```

  
Далее изменим нужные переменные:

```python
SECRET_KEY = str(os.getenv('SECRET_KEY'))

DEBUG = os.getenv('DEBUG')=='True'

ALLOWED_HOSTS = str(os.getenv('DJANGO_ALLOWED_HOSTS')).split(" ")

CACHES = {
    'default': {
        'BACKEND': str(os.getenv('CACHES_BACKEND')),
        'LOCATION': str(os.getenv('CACHES_LOCATION')),
    }
}

INTERNAL_IPS = str(os.getenv('INTERNAL_IPS')).split(" ")
```

Теперь изменим расположение нашего проекта. Для этого в корне создадим папку `app` и переместим в неё проект вместе с `Dockerfile`.

![[Pasted image 20240623183118.png]]

А в файл `.env` добавим следующий код:

```bash
DEBUG = True
SECRET_KEY = 'django-insecure-xxxxxxxxxxxx'
DJANGO_ALLOWED_HOSTS = '127.0.0.1'
CSRF_TRUSTED_ORIGINS = 'http://127.0.0.1'
CACHES_BACKEND = 'django.core.cache.backends.locmem.LocMemCache'
CACHES_LOCATION = 'unique-snowflake'
INTERNAL_IPS = '127.0.0.1'
```

Теперь, каждый раз выполняя сборку контейнеров, у нас будут выполняться следующий процесс:

1. При запуске контейнера будет читаться файл `.env` содержащий какие-то значения;
2. Значения из файла будут помещены как глобальные переменные проекта (переменные окружения);
3. Django, через библиотеку `os.getenv`, читает некоторые переменные из окружения и подставляет где нужно.

Таким образом, если мы захотим поменять настройки, нам не придется еще раз редактировать `settings.py` или `docker-compose.yml`.

  
Затем добавьте файл `docker-compose.yml` в корень проекта:

```yml
# Задаём имя проекта
name: htmx-books-test

services:
  web:
    # Указываем директорию ./app, в которой содержится Dockerfile для сборки образа
    build: ./app
    # Запускаем встроенный сервер Django
    command: python manage.py runserver 0.0.0.0:8000
    # Пробрасываем 8000 порт контейнера на 8000 порт локалхоста(127.0.0.1:8000)
    ports:
      - 127.0.0.1:8000:8000
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env
```



Создадим файл `.dockerignore` в папке нашего проекта(app), чтобы исключить попадание лишних директорий и файлов в контейнер:

```
venv
.idea
Dockerfile*
.dockerignore
```

Перед выполнением следующих шагов проверьте в Docker Desktop запущенные контейнеры, их необходимо остановить. Теперь попробуем создать наш образ Docker Compose:

```bash
sudo docker compose build
```

После создания образа запустите контейнер:

```bash
sudo docker-compose up -d
```

Опция `-d` или `--detach` используется для создания и запуска контейнеров в фоновом режиме.

### PostgreSQL

Что бы мы могли работать с PostgreSQL нам нужно добавить базу данных в настройки Django, а так же установить некоторые зависимости для самого Django. За счет них мы сможем выполнять подключения к базе и выполнять запросы.

Для создания базы данных мы обновим файл `docker-compose.yml` добавив блок под названием `db`. В этом блоке мы пропишем учетные данные пользователя и имя базы, и том, на котором будем хранить базу. Обратите внимание на версию образа postgres, возможно вы захотите её изменить.

```yml
# Задаём имя проекта
name: htmx-books-test

services:
  web:
    # Указываем директорию ./app, в которой содержится Dockerfile для сборки образа
    build: ./app
    # Запускаем встроенный сервер Django
    command: python manage.py runserver 0.0.0.0:8000
    # Пробрасываем 8000 порт контейнера на 8000 порт локалхоста(127.0.0.1:8000)
    ports:
      - 127.0.0.1:8000:8000
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env
  db: # Берём образ БД PostgreSQL версии 15 
    image: postgres:15 # Примонтируем том postgres-data к директории /var/lib/postgresql/data контейнера db 
    volumes: - postgres-data:/var/lib/postgresql/data 
    # Файл содержащий переменные окружения для контейнера
    env_file: 
       - .env # Используем значения переменных окружения из .env файла \
    environment: 
       - POSTGRES_USER=${SQL_USER}
       - POSTGRES_PASSWORD=${SQL_PASSWORD}
       - POSTGRES_DB=${SQL_DATABASE} 
volumes: # Объявляем том postgres-data для хранения данных PostgreSQL 
  postgres-data:
```
Обычно в контейнерах базы данных без указания тома (volume) не запускают (исключения локальная разработка и тесты). Если вам нужно запускать базу в контейнере, то скорее всего вы будете делать это не один раз. В обычном случае, если не использовать том (volume) для контейнера с БД, каждое пересоздание контейнера приведет к уничтожению данных в БД. В случае выше мы описали создание тома `postgres-data`, который будет хранить данные на случай пересоздания контейнера.

  
Django тоже нужно знать какой логин и пароль, а так же имя базы, использует Postgres. Что бы мы этим могли удобно управлять - обновим файл где храним переменные окружения:

```
DEBUG = True
SECRET_KEY = 'django-insecure-xxxxxxxxxxxx'
DJANGO_ALLOWED_HOSTS = '127.0.0.1'
CSRF_TRUSTED_ORIGINS = 'http://127.0.0.1'
CACHES_BACKEND = 'django.core.cache.backends.locmem.LocMemCache'
CACHES_LOCATION = 'unique-snowflake'
INTERNAL_IPS = '127.0.0.1'

SQL_ENGINE=django.db.backends.postgresql
SQL_DATABASE=book_django
SQL_USER=book_django
SQL_PASSWORD=pass_book_django
SQL_HOST=db
SQL_PORT=5432
DATABASE=postgres
```


Нам еще раз нужно отредактировать файл `setting.py`, и изменить значения переменной `DATABASES`, хранящие настройки для баз данных:

```python
DATABASES = {
    "default": {
        "ENGINE": str(os.getenv("SQL_ENGINE")),
        "NAME": str(os.getenv("SQL_DATABASE")),
        "USER": str(os.getenv("SQL_USER")),
        "PASSWORD": str(os.getenv("SQL_PASSWORD")),
        "HOST": str(os.getenv("SQL_HOST")),
        "PORT": str(os.getenv("SQL_PORT")),
    }
}
```

  
И добавим в файл зависимостей `app/requirements.txt` следующие строки:

```bash
psycopg==3.1.12
psycopg-binary==3.1.12
```

  
Выполним билд и запуск наших контейнеров еще раз:

```bash
sudo docker-compose up -d --build
```

Запустите миграции:

```bash
sudo docker-compose exec web python manage.py migrate --noinput
```

Убедитесь, что были созданы таблицы Django:

```bash
sudo docker-compose exec db psql --username=book_django --dbname=book_django

\l
```


### Memcached
Чтобы продемонстрировать наш пример, мы будем использовать локальный экземпляр Memcached в качестве сервера кэширования. Чтобы запустить локальный сервер Memcached, мы используем docker-образ Memcached, что значительно снижает наши усилия по настройке.

Давайте подготовим файл docker-compose, который выглядит следующим образом:

```bash
# Задаём имя проекта
name: htmx-books-test

services:
  web:
    # Указываем директорию ./app, в которой содержится Dockerfile для сборки образа
    build: ./app
    # Запускаем встроенный сервер Django
    command: python manage.py runserver 0.0.0.0:8000
    # Пробрасываем 8000 порт контейнера на 8000 порт локалхоста(127.0.0.1:8000)
    ports:
      - 127.0.0.1:8000:8000
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env
    # Дожидаемся запуска контейнеров db и memcached
    depends_on:
      - db
      - memcached

  db:
    # Берём образ БД PostgreSQL версии 15
    image: postgres:15
    # Примонтируем том postgres-data к директории /var/lib/postgresql/data контейнера db
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env
    # Используем значения переменных окружения из .env файла
    environment:Чтобы продемонстрировать наш пример, мы будем использовать локальный экземпляр Memcached в качестве сервера кэширования. Чтобы запустить локальный сервер Memcached, мы используем docker-образ Memcached, что значительно снижает наши усилия по настройке.

Давайте подготовим файл docker-compose, который выглядит следующим образом:

# Задаём имя проекта
name: htmx-books-test

services:
  web:
    # Указываем директорию ./app, в которой содержится Dockerfile для сборки образа
    build: ./app
    # Запускаем встроенный сервер Django
    command: python manage.py runserver 0.0.0.0:8000
    # Пробрасываем 8000 порт контейнера на 8000 порт локалхоста(127.0.0.1:8000)
    ports:
      - 127.0.0.1:8000:8000
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env
    # Дожидаемся запуска контейнеров db и memcached
    depends_on:
      - db
      - memcached

  db:
    # Берём образ БД PostgreSQL версии 15
    image: postgres:15
    # Примонтируем том postgres-data к директории /var/lib/postgresql/data контейнера db
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env
    # Используем значения переменных окружения из .env файла
    environment:
      - POSTGRES_USER=${SQL_USER}
      - POSTGRES_PASSWORD=${SQL_PASSWORD}
      - POSTGRES_DB=${SQL_DATABASE}

  memcached:
    # Берём образ Мemcached версии 1.6.21
    image: memcached:1.6.21

volumes:
  # Объявляем том postgres-data для хранения данных PostgreSQL
  postgres-data:

Также изменим наш файл с переменными .env:

DEBUG = True
SECRET_KEY = 'django-insecure-xxxxxxxxxxxx'
DJANGO_ALLOWED_HOSTS = '127.0.0.1'
CSRF_TRUSTED_ORIGINS = 'http://127.0.0.1'
CACHES_BACKEND = 'django.core.cache.backends.memcached.PyMemcacheCache'
CACHES_LOCATION = 'memcached:11211'
INTERNAL_IPS = '127.0.0.1'

SQL_ENGINE=django.db.backends.postgresql
SQL_DATABASE=book_django
SQL_USER=book_django
SQL_PASSWORD=pass_book_django
SQL_HOST=db
SQL_PORT=5432
DATABASE=postgres


Выполним билд и запуск наших контейнеров еще раз:

docker-compose up -d --build
      - POSTGRES_USER=${SQL_USER}
      - POSTGRES_PASSWORD=${SQL_PASSWORD}
      - POSTGRES_DB=${SQL_DATABASE}

  memcached:
    # Берём образ Мemcached версии 1.6.21
    image: memcached:1.6.21

volumes:
  # Объявляем том postgres-data для хранения данных PostgreSQL
  postgres-data:
```

  
Также изменим наш файл с переменными `.env`:

```bash
DEBUG = True
SECRET_KEY = 'django-insecure-xxxxxxxxxxxx'
DJANGO_ALLOWED_HOSTS = '127.0.0.1'
CSRF_TRUSTED_ORIGINS = 'http://127.0.0.1'
CACHES_BACKEND = 'django.core.cache.backends.memcached.PyMemcacheCache'
CACHES_LOCATION = 'memcached:11211'
INTERNAL_IPS = '127.0.0.1'

SQL_ENGINE=django.db.backends.postgresql
SQL_DATABASE=book_django
SQL_USER=book_django
SQL_PASSWORD=pass_book_django
SQL_HOST=db
SQL_PORT=5432
DATABASE=postgres

```

  
Выполним билд и запуск наших контейнеров еще раз:

```bash
sudo docker-compose up -d --build
```


## Gunicorn, Nginx в Docker Compose

### Gunicorn

Вместо встроенного веб-сервера в Django, который подходит только для разработки, мы будем использовать веб-сервер Gunicorn. Он будет работать только как сервер приложений. Выдача статического контента будет возложена на веб-сервер Nginx, он же будет выступать в качестве обратного прокси для сервера приложений Gunicorn, что позволит снизить нагрузку на него.

Gunicorn, так же как и библиотеку для PostgreSQL, нужно добавить в файл зависимостей `requerements.txt`:

```
gunicorn==21.2.0
```

  
Что-бы было удобно использовать образ для локальной разработки и для продакшена, создадим второй файл с названием `docker-compose.prod.yml`. Он будет аналогичен предыдущему образу за исключением нескольких моментов: 

```
# Задаём имя проекта
name: htmx-books-prod

services:
  web:
    # Указываем директорию ./app, в которой содержится Dockerfile.prod для сборки образа
    build: ./app
    # Запускаем сервер Gunicorn
    command: gunicorn core.wsgi:application --bind 0.0.0.0:8000
    # Пробрасываем 8000 порт контейнера на 8000 порт локалхоста(127.0.0.1:8000)
    ports:
      - 127.0.0.1:8000:8000
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env.prod
    # Дожидаемся запуска контейнеров db и memcached
    depends_on:
      - db
      - memcached

  db:
    # Берём образ БД PostgreSQL версии 15
    image: postgres:15
    # Примонтируем том postgres-data к директории /var/lib/postgresql/data контейнера db
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env.prod
    # Используем значения переменных окружения из .env.prod файла
    environment:
      - POSTGRES_USER=${SQL_USER}
      - POSTGRES_PASSWORD=${SQL_PASSWORD}
      - POSTGRES_DB=${SQL_DATABASE}

  memcached:
    # Берём образ Мemcached версии 1.6.21
    image: memcached:1.6.21

volumes:
  # Объявляем том postgres-data для хранения данных PostgreSQL
  postgres-data:
```

В этом файле мы изменили строку команды запуска вебсервера, в контейнере `web`. Теперь эта команда будет запускать вебсервер Gunicorn. Кроме это мы изменили имя `.env` на `.env.prod` для контейнеров `web` и `db`.

Создадим файл `.env.prod`, в который поместим те же переменные, как и в файле `.env`.

Подразумевается, что для локальной разработки и что для деплоя, вы будете использовать разные значения этих переменных:

```
DEBUG = False
SECRET_KEY = 'django-insecure-xxxxxxxxxxxx'
DJANGO_ALLOWED_HOSTS = '127.0.0.1'
CSRF_TRUSTED_ORIGINS = 'http://127.0.0.1'
CACHES_BACKEND = 'django.core.cache.backends.memcached.PyMemcacheCache'
CACHES_LOCATION = 'memcached:11211'
INTERNAL_IPS = '127.0.0.1'

SQL_ENGINE=django.db.backends.postgresql
SQL_DATABASE=book_django
SQL_USER=book_django
SQL_PASSWORD=pass_book_django
SQL_HOST=db
SQL_PORT=5432
DATABASE=postgres
```

  
Теперь добавим новый маршрут в главный файл `urls.py` проекта:

```python
from django.conf import settings
from django.conf.urls.static import static

if settings.DEBUG:
    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)
```

Это необходимо чтобы статические файлы работали и при использовании вебсервера Gunicorn. Естественно только когда будет включена отладка `DEBUG = True`.

  
Теперь необходимо изменить настройки проекта в файле `settings.py`, указав директорию для хранения статических файлов. В данную директорию будут помещены все статические файлы проекта, при выполнении команды сбора - `collectstatic`:

```python
import sys

if sys.argv[1] == 'runserver':
    STATICFILES_DIRS = [os.path.join(BASE_DIR, 'static'),]
else:
    STATIC_ROOT = os.path.join(BASE_DIR, 'static')
```

  
Выполним остановку предыдущих контейнеров, удалим их:

```
sudo docker compose down -v
```

Выполним билд нового контейнера для деплоя:

```bash
sudo docker compose -f docker-compose.prod.yml up -d --build
```

  
Применим миграции, при которых будет создана структура нашей базы данных `book_django`:

```bash
sudo docker compose -f docker-compose.prod.yml exec web python manage.py migrate --noinput
```

  
Соберём статичные файлы в директории, контейнера `web`, указанной в параметре настроек проекта `STATIC_ROOT`.

```bash
sudo docker compose -f docker-compose.prod.yml exec web python manage.py collectstatic --noinput
```

Теперь создадим образ докера для создания контейнера с Django.

В данном примере будет использоваться мульти-образ для экономии места. `builder` - это временный образ с помощью которого будут созданы бинарные файлы библиотек Python. После создания образа `builder` с него будут скопированы файлы в наш основной образ.

Создадим файл `app/Dockerfile.prod`:

``` Dockerfile
###########
# BUILDER #
###########

FROM python:3.12.0-alpine as builder

WORKDIR /usr/src/app

ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1

# установка зависимостей
RUN apk update \
    && apk add postgresql-dev gcc python3-dev musl-dev
RUN pip install --upgrade pip

# установка зависимостей
COPY ./requirements.txt .
RUN pip wheel --no-cache-dir --no-deps --wheel-dir /usr/src/app/wheels -r requirements.txt


#########
# FINAL #
#########

FROM python:3.12.0-alpine

ENV HOME=/home/app
ENV APP_HOME=/home/app/web

# создаем домашнюю директорию для пользователя(/home/app) и директорию для проекта(/home/app/web)
# создаем группу app и отдельного пользователя app
RUN mkdir -p $APP_HOME \
    && addgroup -S app \
    && adduser -S app -G app \
    && apk update \
    && apk add libpq

# копирование из builder и установка зависимостей
COPY --from=builder /usr/src/app/wheels /wheels
RUN pip install --no-cache /wheels/*

# устанавливаем рабочую директорию
WORKDIR $APP_HOME

# копирование проекта Django в рабочую директорию
COPY . .

# изменение владельца, для всех директорий и файлов проекта, на пользователя app
RUN chown -R app:app .

# изменение рабочего пользователя на app
USER app

RUN chmod +x entrypoint.prod.sh
ENTRYPOINT ["./entrypoint.prod.sh"]
```

В образе мы создали пользователя `app` и его группу `app`. Это делается для того, что бы не использовать пользователя `root`, который используется по умолчанию в контейнерах Docker.

Создадим файл `entrypoint.prod.sh` в папке `app`, рядом с `Dockerfile.prod`

```bash
#!/bin/sh

if [ "$DATABASE" = "postgres" ]
then
    echo "Postgres еще не запущен..."

    # Проверяем доступность хоста и порта
    while ! nc -z $SQL_HOST $SQL_PORT; do
      sleep 1
    done

    echo "PostgreSQL запущен"
fi

exec "$@"
```

Данный файл необходим чтобы проверить работоспособность PostgreSQL перед применением миграции и запуском сервера Gunicorn.


Изменим файл `docker-compose.prod.yml`, чтобы про сборке образа `web` использовался новый файл - `Dockerfile.prod`:

```yml
# Задаём имя проекта
name: htmx-books-prod

services:
  web:
    # Указываем директорию ./app, в которой содержится Dockerfile.prod для сборки образа
    build:
      context: ./app
      dockerfile: Dockerfile.prod
    # Запускаем сервер Gunicorn
    command: gunicorn core.wsgi:application --bind 0.0.0.0:8000
    # Пробрасываем 8000 порт контейнера на 8000 порт локалхоста(127.0.0.1:8000)
    ports:
      - 127.0.0.1:8000:8000
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env.prod
    # Дожидаемся запуска контейнеров db и memcached
    depends_on:
      - db
      - memcached

  db:
    # Берём образ БД PostgreSQL версии 15
    image: postgres:15
    # Примонтируем том postgres-data к директории /var/lib/postgresql/data контейнера db
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env.prod
    # Используем значения переменных окружения из .env.prod файла
    environment:
      - POSTGRES_USER=${SQL_USER}
      - POSTGRES_PASSWORD=${SQL_PASSWORD}
      - POSTGRES_DB=${SQL_DATABASE}

  memcached:
    # Берём образ Мemcached версии 1.6.21
    image: memcached:1.6.21

volumes:
  # Объявляем том postgres-data для хранения данных PostgreSQL
  postgres-data:
```

  
Протестируем:

```bash
sudo docker compose -f docker-compose.prod.yml down -v
sudo docker compose -f docker-compose.prod.yml up -d --build
sudo docker compose -f docker-compose.prod.yml exec web python manage.py migrate --noinput
sudo docker compose -f docker-compose.prod.yml exec web python manage.py collectstatic --noinput
```


### Nginx

Nginx будет использоваться в качестве обратного прокси сервера для сервера приложений Gunicorn, так-же на него будет возложена работа по выдаче статических файлов.

Первое, что мы сделаем - добавим следующие строки в файл `docker-compose.prod.yml`:

```
# Задаём имя проекта
name: htmx-books-prod

services:
  web:
    # Указываем директорию ./app, в которой содержится Dockerfile.prod для сборки образа
    build:
      context: ./app
      dockerfile: Dockerfile.prod
    # Запускаем сервер Gunicorn
    command: gunicorn core.wsgi:application --bind 0.0.0.0:8000
    # Пробрасываем 8000 порт контейнера на 8000 порт локалхоста(127.0.0.1:8000)
    ports:
      - 127.0.0.1:8000:8000
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env.prod
    # Дожидаемся запуска контейнеров db и memcached
    depends_on:
      - db
      - memcached

  db:
    # Берём образ БД PostgreSQL версии 15
    image: postgres:15
    # Примонтируем том postgres-data к директории /var/lib/postgresql/data контейнера db
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env.prod
    # Используем значения переменных окружения из .env.prod файла
    environment:
      - POSTGRES_USER=${SQL_USER}
      - POSTGRES_PASSWORD=${SQL_PASSWORD}
      - POSTGRES_DB=${SQL_DATABASE}

  memcached:
    # Берём образ Мemcached версии 1.6.21
    image: memcached:1.6.21

  nginx:
    # Указываем директорию ./nginx, в которой содержится Dockerfile для сборки образа
    build: ./nginx
    # Пробрасываем 80 порт контейнера на 80 порт локальной машины(порт будет доступен из вне)
    ports:
      - 80:80
    # Дожидаемся запуска контейнера web
    depends_on:
      - web

volumes:
  # Объявляем том postgres-data для хранения данных PostgreSQL
  postgres-data:
```

В примере выше мы открываем стандартный 80й порт для посетителей сайта, который будет перенаправлять пакеты на 80й порт контейнера `nginx`. Вы можете изменить 80й порт на любой другой.

  
Создадим директорию `nginx`, в которой будут хранится конфигурационный файл вебсервера `htmx_book.conf` и файл `Dockerfile`.

![](https://ucarecdn.com/c49a17bb-0ffb-4ddf-9ea4-2ae6f2c881a0/)

  
В файл `htmx_book.conf` добавим следующий код:

```
upstream htmx_book {
    # Список бэкэнд серверов для проксирования
    server web:8000;
}

server {
    listen 80;
    # Ваш домен
    server_name 127.0.0.1;
    # Параметры проксирования
    location / {
        # Если будет открыта корневая страница
        # все запросу пойдут к одному из серверов
        # в upstream htmx_book
        proxy_pass http://htmx_book;
        # Устанавливаем заголовки
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Host $host;
        # Отключаем перенаправление
        proxy_redirect off;
    }
}
```

  
Что бы файл конфигурации попал в контейнер, мы должны создать отдельный файл `Dockerfile`:

```no-highlight
FROM nginx:1.25

RUN rm /etc/nginx/conf.d/default.conf
COPY htmx_book.conf /etc/nginx/conf.d/
```

  
После создания контейнера Nginx, мы закроем прямой доступ к контейнеру с Django через 8000й порт.  
К контейнеру с Django будет разрешено обращаться только сервисам Docker.

В результате наш файл `docker-compose.prod.yml` будет выглядеть следующим образом:

```
# Задаём имя проекта
name: htmx-books-prod

services:
  web:
    # Указываем директорию ./app, в которой содержится Dockerfile.prod для сборки образа
    build:
      context: ./app
      dockerfile: Dockerfile.prod
    # Запускаем сервер Gunicorn
    command: gunicorn core.wsgi:application --bind 0.0.0.0:8000
    # Пробрасываем 8000 порт контейнера на 8000 порт локалхоста(127.0.0.1:8000)
    ports:
      - 127.0.0.1:8000:8000
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env
    # Дожидаемся запуска контейнеров db и memcached
    depends_on:
      - db
      - memcached

  db:
    # Берём образ БД PostgreSQL версии 15
    image: postgres:15
    # Примонтируем том postgres-data к директории /var/lib/postgresql/data контейнера db
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env
    # Используем значения переменных окружения из .env файла
    environment:
      - POSTGRES_USER=${SQL_USER}
      - POSTGRES_PASSWORD=${SQL_PASSWORD}
      - POSTGRES_DB=${SQL_DATABASE}

  memcached:
    # Берём образ Мemcached версии 1.6.21
    image: memcached:1.6.21

  nginx:
    # Указываем директорию ./nginx, в которой содержится Dockerfile для сборки образа
    build: ./nginx
    # Пробрасываем 80 порт контейнера на 80 порт локальной машины(порт будет доступен из вне)
    ports:
      - 80:80
    # Дожидаемся запуска контейнера web
    depends_on:
      - web

volumes:
  # Объявляем том postgres-data для хранения данных PostgreSQL
  postgres-data:
```


## Настройка Docker-Compose для статических и медиа файлов

### Настройки для статических файлов

В прошлых шагах мы использовали сервер Gunicorn для выдачи статических файлов. Это можно использовать только при отладке или тестировании проекта, данный сервер не предназначен для работы со статическими файлами - это сервер приложений.

Необходимо переложить эту работу на другой вебсервер, например на NGINX, который у нас в проекте используется в качестве обратного прокси-сервера. Соответственно у контейнера с вебсервером NGINX должен быть доступ к статическим файлам проекта.

На данный момент статические файлы хранятся в директории `/home/app/web/static` контейнера `web`, они помещаются в эту директорию после выполнения команды `collectstatic`, которая собирает их со всего Django-проекта.

Данный способ хранения статических файлов имеет существенные недостатки: необходимость собирать файлы каждый раз при перезапуске контейнера(когда контейнер удаляется) и недоступность этих файлов для других контейнеров.

Решить данную проблему можно с помощью использования тома(volume), который может быть доступен для любого контейнера.

Для этого создадим новый том с именем `static-data` в файле `docker-compose.prod.yml`. Полное содержимое данного файла должно быть таким:

```
# Задаём имя проекта
name: htmx-books-prod

services:
  web:
    # Указываем директорию ./app, в которой содержится Dockerfile.prod для сборки образа
    build:
      context: ./app
      dockerfile: Dockerfile.prod
    # Запускаем сервер Gunicorn
    command: gunicorn core.wsgi:application --bind 0.0.0.0:8000
    # Примонтируем том static-data к директории /home/app/web/static контейнера web
    volumes:
      - static-data:/home/app/web/static
    # Пробрасываем 8000 порт контейнера на 8000 порт локалхоста(127.0.0.1:8000)
    ports:
      - 127.0.0.1:8000:8000
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env.prod
    # Дожидаемся запуска контейнеров db и memcached
    depends_on:
      - db
      - memcached

  db:
    # Берём образ БД PostgreSQL версии 15
    image: postgres:15
    # Примонтируем том postgres-data к директории /var/lib/postgresql/data контейнера db
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # Файл содержащий переменные окружения для контейнера
    env_file:
      - .env.prod
    # Используем значения переменных окружения из .env.prod файла
    environment:
      - POSTGRES_USER=${SQL_USER}
      - POSTGRES_PASSWORD=${SQL_PASSWORD}
      - POSTGRES_DB=${SQL_DATABASE}

  memcached:
    # Берём образ Мemcached версии 1.6.21
    image: memcached:1.6.21

  nginx:
    # Указываем директорию ./nginx, в которой содержится Dockerfile для сборки образа
    build: ./nginx
    # Примонтируем том static-data к директории /home/app/web/static контейнера nginx
    volumes:
      - static-data:/home/app/web/static
    # Пробрасываем 80 порт контейнера на 80 порт локальной машины(порт будет доступен из вне)
    ports:
      - 80:80
    # Дожидаемся запуска контейнера web
    depends_on:
      - web

volumes:
  # Объявляем том postgres-data для хранения данных PostgreSQL
  postgres-data:
  # Объявляем том static-data для хранения статических файлов
  static-data:
```

Обратите внимание, что мы примонтировали том `static-data` к директориям `/home/app/web/static` контейнеров `web` и `nginx`. Это не одна и та же директория, это директории разных контейнеров.

Для контейнера `web` эта директория задаётся в файле настроек `settings.py`, в параметре `STATIC_ROOT`.

Для контейнера `nginx` эта директория задаётся в конфигурационном файле `NGINX`.

Теперь оба контейнера получат доступ к данному тому. Для контейнера `web` этот доступ необходим для помещения статических файлов в данный том(команда `collectstatic`), а для контейнера `nginx` - уже для непосредственной выдачи файлов вебсервером.

**Внимание!** В данном файле, команда запуска вебсервера для проекта с именем `core`. Если у вас используется другое имя проекта, измените данную команду следующим образом:

```bash
command: gunicorn <имя_проекта>.wsgi:application --bind 0.0.0.0:8000
# например для проекта с именем django_htmx:
command: gunicorn django_htmx.wsgi:application --bind 0.0.0.0:8000
```

  
Теперь необходимо отредактировать конфигурационный файл NGINX `htmx_book.conf`, добавив секцию для статических файлов. Полное содержимое данного файла должно быть таким:

```
upstream htmx_book {
    # Список бэкэнд серверов для проксирования
    server web:8000;
}

server {
    listen 80;
    # Ваш домен
    server_name 127.0.0.1;
    # Параметры проксирования
    location / {
        # Если будет открыта корневая страница
        # все запросу пойдут к одному из серверов
        # в upstream htmx_book
        proxy_pass http://htmx_book;
        # Устанавливаем заголовки
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Host $host;
        # Отключаем перенаправление
        proxy_redirect off;
    }
    # подключаем статические файлы
    location /static/ {
        alias /home/app/web/static/;
    }
}
```

Теперь обработкой статических файлов будет заниматься NGINX, без участия Gunicorn. При запросах статических файлов, NGINX будет выдавать их из тома `static-data`, так как данный том примонтирован к директории `/home/app/web/static/` контейнера `nginx`.


## Полезное и удобное

Иногда необходимо настроить автообновление сертификатов certbot. Шаги для этого"
1. Создаём файл nginx.conf (пока без инфы с сертификатами)
``` nginx
http {
    server {
        listen 80;
        server_name panel.geo.expert;

        location /.well-known/acme-challenge/ {
            root /var/www/certbot;
        }

        location / {
            proxy_pass http://web:8000;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
```

2. Добавляем certbot в docker compose (**поменять домен и почту на актуальные**)
```docker
services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./data/certbot/conf:/etc/letsencrypt
      - ./data/certbot/www:/var/www/certbot
    depends_on:
      - web
    networks:
      - frontend
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 5

  certbot:
    image: certbot/certbot
    volumes:
      - ./data/certbot/conf:/etc/letsencrypt
      - ./data/certbot/www:/var/www/certbot
    command: certonly --webroot -w /var/www/certbot --email mail@example.com --agree-tos --no-eff-email -d domain --non-interactive
    depends_on:
      nginx:
        condition: service_healthy
    networks:
      - frontend
```

3. Поднимаем контейнер
```bash
sudo docker compose -f <имя_файла> up --build
```

Как всё запустится - останавливаем
4. Обновляем конфиг (меняем домен!)
```docker
http {
    server {
        listen 80;
        server_name panel.geo.expert;

        location /.well-known/acme-challenge/ {
            root /var/www/certbot;
        }

        location / {
            return 301 https://$host$request_uri;
        }
    }

    server {
        listen 443 ssl;
        server_name panel.geo.expert;

        ssl_certificate /etc/letsencrypt/live/domain/fullchain.pem;
        ssl_certificate_key /etc/letsencrypt/live/domain/privkey.pem;

        location / {
            proxy_pass http://web:8000;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
```

5.  Перезапускаем контейнер


**Certbot на 5 шаге должен упасть (при запуске). Это нормально.**