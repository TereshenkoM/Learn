
## Как PostgreSQL хранит данные?

* В файлах
* Файлы разбиты на блоки по 8 килобайт, блоки называют страницами
* Страница - минимальным объём, который PostgreSQL объём, который PostgreSQL может считать с диска и записать на диск
* Считать 1 строку нельзя, можно считать только одну страницу, на которой есть эта строка
* После считывания она попадает в буферный кеш - область оперативной памяти и хранится там, пока другие данные её не вытeснят
* Если данные не помещаются в 8 KB, то они кладутся в отдельную TOAST табличку, а в основной таблице сохраняется ссылка на TOAST-таблицу

## Коварные широкие таблицы

Считывать 1 буфер быстрее, чем 1000. Как это знание использовать?
Например:
* Использовать связь o2o вместо создания широких таблиц
* Часто нужные данные, которые используются вместе, храним в одной таблице, а остальной массив данных храним отдельно в другой или в других таблицах
* Тогда при считывании основных данных с диска не будут читаться нужные редко данные


При этом не стоит бояться join, в postgreSQL они работают очень быстро.


## Небольшой промежуточный итог

1. Всегда указываем поля, которые достаём. Всегда!
2. Всегда начинаем с нормализованной схемы, используем таблицы со связью один к одному вместо создания широких таблиц


## EXPLAIN

PostgreSQL даёт возможность посмотреть, как выполняется SQL-запрос. Для этого перед ним надо написать EXPLAIN.

Например
```sql
explain select * from users
```

### Что выводит EXPLAIN?

* План выполнения запроса
* В PostgreSQL есть оптимизатор запросов. Он строит план выполнения запроса для наиболее эффективного его выполнения.

### Зачем читать этот план выполнения запроса?
* Чтобы понять, почему запрос работает неэффективно
* Чтобы переписать запрос на более эффективный
* Чтобы накинуть индекс
* Чтобы понять, что стоит кластеризовать таблицу
* Чтобы понять, что надо собрать статистку или уточнить её или расширить её
* Чтобы понять, что надо изменить настройки PostgreSQL или сервера - например, добавить оперативной памяти


#### Кластеризация таблицы

Это выстраивание таблицы в соответствии с каким-то индексом.  

Предположим в колонке с сотрудниками есть таблица с полем дата трудоустройства.
Мы создаём индекс по этой дате трудоустройства (в отсортированном виде). И мы можем перестроить всю таблицу так, чтобы все строчки хранились в порядке их трудоустройства.


## Как читать EXPLAIN

Чтобы научиться читать EXPLAIN надо понимать как работает PostgresQL

Пример EXPLAIN анализа

![[Pasted image 20250717133032.png]]
### Методы доступа к данным

Нам надо достать какие-то данные, хранящиеся в БД. Как это сделать?
* Полное сканирование таблицы - seq scan, sequential scan
	Просто берём и читаем последовательно всю таблицу. Если таблица большая это долго и  уныло. Но иногда это единственный выбор. 
	![[Pasted image 20250717133654.png]]
	Где:
	Слева - предполагаемые цифры, а справа - актуальные
	
	* seq can - последовательное сканирование таблицы employee
	* сost, actual_time - оценка стоимости узла (узлов может быть несколько)
		* 0.00 - стоимость вывода первой строки этим узлом (подготовительная работа до первой строки)
		* 173528.84 - стоимость вывода всех строк этим узлом
	* rows - строк в этом узле
* Сканирование с использованием индекса
	* Индексное сканирование - index scan
		![[Pasted image 20250717135610.png]]
		Где:
		Слева - предполагаемые цифры, а справа - актуальные

		Как работает:
		* Читаем индекс, найдя в нём нужное значение нашей колонки
			Индекс - упорядоченная структура, мы быстро находим там нужное значение даже для огромной таблицы
		* Найденная в индексе запись ссылается на конкретную страницу таблицы, которая хранит нужную на строку
			Мы считываем страницу таблицы и вуаля!

		**Когда мы фильтруем по колонке с индексом - индекс не всегда используется!**
		![[Pasted image 20250717140458.png]]
		Селективность - доля выбираемых строк. Отношение выбранных строк к общему количеству строк. От 0 до 1. Единица - все строки. 0.00001 - выбирается малая часть строк. Высокая селективность означает, что выбирается малая доля всех строк.
		
		**Индекс используется только при высокой селективности**
		* Если надо достать много строк таблицы - назачем читать индекc, легче прочесть всю строку целиком
		* Потому что после чтения индекса надо будет всё равно читать страницы самой таблицы
	
	* Сканирование по битовой карте - bitmap heap scan
		* Тоже используется индекс
		* Позволяет не читать несколько раз одну и ту же страницу для разных строк, сначала составляем битовую карту / маска, в котором указываются страницы на чтение, и потом эти страницы считываются из таблицы
		* Позволяет объединять несколько индексов объединением битовых масок (OR, AND)
	* Сканирование только индекса - index only scan
		* Позволяет не считывать таблицу - если все поля для select есть в самом индексе
		![[Pasted image 20250717141118.png]]

**ИТОГ**
* Достаём малый % данных - Index Scan
* Побольше - Bitmap Index Scan
* Ещё побольше  - Seq Scan
### Что такое стоимость?

Стоимость - коэффициент, который высчитывает оптимизатором постргерса для сравнения разных планов запросов. Складывается из 2-х трудозатрат - диск и процессор. Больше данных читается - выше стоимость.

Тезисно:
* Оценка трудоёмкости выполнения узла (или всего запроса, состоящего из нескольких узлов)
* Входит оценка ресурсов процессора и IO-операций, то есть чтения с диска и записи на диск
* Больше обработка данных процессором - выше стоимость
* Больше данных читается с диска - выше стоимость

Откуда берётся стоимость? 
![[Pasted image 20250717135059.png]]
Это оценка IO-операций Надо считать 75 530 страниц с диска. Стоимость считывания одной страницы равна 1.

![[Pasted image 20250717135251.png]]

![[Pasted image 20250717135329.png]]

#### Зафиксируем

* Стоимость выполнения запросов (cost) - это индикатор, которые позволяет сравнивать стоимость разных запросов и разных планов выполнения запроса
* Больше стоимость - дольше выполняется запрос



### Способы соединения таблиц

* nested loop, вложенные циклы
	* Один цикл вложен в другой
* hash join, соединения хешированием
	* Меньшая таблица хешируется в памяти
	* От колонки соединения берётся хеш и по нему быстро находится значение меньшей таблицы
* merge join, соединения слиянием
	* Используется когда обе таблицы в соединении отсортированы по колонкам соединения или когда стоимость сортировки меньше, чем стоимость других способов соединения

### Как играться с методами доступа и способами соединения таблиц
![[Pasted image 20250717142014.png]]


**Итог**
![[Pasted image 20250717142128.png]]
На что стоить обращать внимание?
* Seq Scan большой таблицы не может быть быстрым
* Стоимость использования explain (analyze, buffer), чтобы смотреть, сколько буферов в каждом узле
* Стоит смотреть на большие отличия в rows и actual rows - это говорит о неверной статистике
* Стоит думать как СУБД - насколько план оптимален и почему он такой  

Стоит использовать explain (analyze, buffers) - фактически буферы - число страниц
![[Pasted image 20250717142604.png]]
Видно, сколько страниц читается на каждом узле:
* shared hit - прочитано из буфера (из оперативной памяти)
* read - прочитано из диска
Если читается много страниц с диска - это не может быть быстро


### Статистика
* Оптимизатор в плане учитывает планируемое количество строк на каждом узле из своей статистике
* Её можно и нужно обновлять
	* Не отключать auto vacuum на сервере
	* Можно принудительно запускать VACUUM ANALYZE для обновления статистики
* Можно уточнять статистику, например через параметр default_statuictics_target

### Более умные индексы
* Составные индексы по нескольким колонкам
* Покрывающие индексы для Index Only Scan
* Индексы по функции - например, индекс по date_trunc(some_date_field)
	* Тогда индекс может использоваться в запросе where
* Частичные индексы
	* Строится на части таблиц, например для строк, которые хранят почти уникальное в таблице значение по нужной колонке


## Короткие и длинные запросы
* Короткие запросы - когда количество строк для получения нужного результата, невелико, независимо от того, насколько велики задействованные таблицы. Короткие запросы могут считывать все строки из маленьких таблиц, но лишь небольшой % строк из больших таблиц 

* Длинные запросы - если селективность запроса низка по крайней мере для одной из больших таблиц, то есть результат, даже если он невелик, определяется почти всеми строками.
	* Результат count от большой таблицы - невелик, но задействованы все строки большой таблицы

### Оптимизация коротких запросов
* Определить наиболее ограничительные критерии и убедиться, что на эти критерии есть индексы
* Подумать об использовании покрывающего индекса для Index Only Scan
* При построении запроса начни писать его с наиболее ограничительной части, добавляя затем к ней соединения
	* Вместо использования соединений и фильтрации его результатов 

### Оптимизация длинных запросов
* Скорее всего OLAP-запрос, аналитический. Убедись, что он не выполняется часто и много для продакшн бд
	* OLTP запросы не должны быть длинными
* Подумай о внедрении инрементальных обновлений
	* Кешируем результаты в отдельной таблице и добавляем в эту таблицу новые значения вместо переработки всей таблицы
* Убедись, что наиболее ограничительная операция выполняется в плане первой, добейся этого
* Добейся того, чтобы большие таблицы читались однократно в плане запроса
* Такие запросы можно гонять на отдельной БД


### Как найти наиболее медленные запросы?
![[Pasted image 20250717145519.png]]
### Настройки
* Можно увеличить work_mem и hash_mem_multiplier для увеличения объёма RAM, доступной для операций внутри запроса, в том числе для операций с hash join
* Можно уменьшить random_page_cost для быстрых SSD (с 4 до 11 например)
* shared_buffers стоит установить в 30-40% от доступной памяти на сервере
* Конечно использовать пулер коннектов (Pgbouncer, Odyssey)

### Ещё
* Денормализация через materialized views, которые по cron'у обновляются
* Кеширование данных в приложении
* Секционирование (разбитие большой таблицы на несколько меньших)