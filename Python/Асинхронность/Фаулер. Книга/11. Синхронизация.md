
Вопросы:
* проблемы однопоточной конкурентности
* использование блокировок для защиты  критических секций
* использование семафоров для ограничения уровня конкурентности
* использование событий для уведомления задач
* использование условий для уведомления задач и захвата ресурса


При написании приложений с несколькими потоками или процессами нужно помнить о возможности состояния гонки при использовании неатомарных операций. Некоторые ошибки, встречающиеся в многопоточных или многопроцессных приложениях исключены, в силу однопоточной природы asyncio, но не совсем.

**Примитивы синхронизации asyncio** могут помочь предотвратить ошибки, свойственные только модели однопоточной конкурентности.


## Природа ошибок в модели однопоточной конкурентности

При работе с многопоточными и многопроцессными приложениями необходимо помнить о состоянии гонки. Это связано с тем, что они могут одновременно модифицировать данные, что может привести к несогласованным состояниям и к повреждению данных.

Частично это обуславливается тем, что некоторые операции неатомарны, т.е. хотя и выглядят как одна операция, на самом деле состоит из нескольких операций.
В модели однопоточной конкурентности мы избегаем состояния гонки. вызываемых неатомарными операциями. В asyncio есть только один поток, который в каждый момент времени исполняет одну строка кода. Это означает, что если операция неатомарна, она всё равно будет доведена до конца и другие сопрограммы не смогут прочитать несогласованные данные.

Пример
```python
import asyncio  
  
  
counter: int = 0  
  
  
async def increment():  
    global counter  
    await asyncio.sleep(0.01)  
    counter += 1  
  
  
async def main():  
    global counter  
  
    for _ in range(1000):  
        tasks = [asyncio.create_task(increment()) for _ in range(100)]  
        await asyncio.gather(*tasks)  
  
        print(counter)  
  
        assert counter == 100  
        counter = 0  
  
  
asyncio.run(main())
```

При выполнении этой программы мы всегда будем видеть 100, хотя операция инкриментирования целого числа не атомарна. 

Означает ли это, что однопоточная конкурентность подарила нам способ избавиться от состояния гонки? **НЕТ**.

Осталось проблема неправильного порядка выполнения нескольких операций. 
Попробуем сделать операцию инкрементирования целого числа неатомарной, на взгляд asyncio.

Для этого мы воспроизведём то, что происходит под копотом при инкрементировании глобального счётчика: чтение, увеличение и запись на старое место. 
Идея в том, что если какой-то код модифицирует состояние, пока корутина приостановлена в await в ожидании завершения другого await, то мы можем получить несогласованное состояние.

Пример
```python
import asyncio  
  
  
counter: int = 0  
  
async def increment():  
    global counter  
    temp_counter = counter  
    temp_counter += 1  
    await asyncio.sleep(0.01)  
    counter = temp_counter  
  
# Упадёт с ошибкой  
# counter = 1  
async def main():  
    global counter  
    for _ in range(1000):  
        tasks = [asyncio.create_task(increment()) for _ in range(100)]  
        await asyncio.gather(*tasks)  
        print(counter)  
        assert counter == 100  
        counter = 0  
  
  
asyncio.run(main())
```

 Поскольку поток всего один, все операции чтения временной переменной выполняются последовательно, т.е. каждая все сопрограммы сохраняют значение 0, потом увеличивают до 1. Затем, как только сон закончился, каждая сопрограмма записывает в счётчик значение 1. Т.е. несмотря на 100 сопрограмм, новым значением станет 1.'

Чтобы лучше понять сконструируем более сложное состояние гонки. Создадим словарь, содержащий несколько подключенный пользователей, и для каждого имитируем сокет. Отправим всем пользователям сообщение и вручную имитируем отключение одного из них в момент отправки

```python
import asyncio  
  
  
class MockSocket:  
    def __init__(self):  
        self.socket_closed = False  
  
    async def send(self, msg: str):  
        if self.socket_closed:  
            raise Exception('Сокет закрыт')  
  
        print(f'Отправляется: {msg}')  
        await asyncio.sleep(1)  
        print(f'Отправлено: {msg}')  
  
    def close(self):  
        self.socket_closed = True  
  
  
user_name_to_sockets = {  
    'John': MockSocket(),  
    'Terry': MockSocket(),  
    'Graham': MockSocket(),  
    'Eric': MockSocket()  
}  
  
  
async def user_disconnect(username: str):  
    print(f'{username} отключен')  
    socket = user_name_to_sockets.pop(username)  
    socket.close()  
  
  
async def message_all_users():  
    print('Создаются задачи отправки сообщений')  
    messages = [  
        socket.send(f'Привет, {user}')  
        for user, socket in user_name_to_sockets.items()  
    ]    await asyncio.gather(*messages)  
  
  
async def main():  
    await asyncio.gather(message_all_users(), user_disconnect('Eric'))  
  
  
asyncio.run(main())
```

Вывод

```
Создаются задачи отправки сообщений
Eric отключен
Отправляется: Привет, John
Отправляется: Привет, Terry
Отправляется: Привет, Graham
Traceback (most recent call last):
  File "/home/user/Learn/Примеры кода (Python)/py_async/fauler/chapter_11/listing_11_3.py", line 43, in <module>
    asyncio.run(main())
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/user/Learn/Примеры кода (Python)/py_async/fauler/chapter_11/listing_11_3.py", line 41, in main
    await asyncio.gather(message_all_users(), user_disconnect('Eric'))
  File "/home/user/Learn/Примеры кода (Python)/py_async/fauler/chapter_11/listing_11_3.py", line 38, in message_all_users
    await asyncio.gather(*messages)
  File "/home/user/Learn/Примеры кода (Python)/py_async/fauler/chapter_11/listing_11_3.py", line 10, in send
    raise Exception('Сокет закрыт')
Exception: Сокет закрыт
```

Именно такие типы ошибок можно встретить в модели однопоточной конкурентности. Поток выполнения упирается в точку приостановки await, после чего начинает работать другая сопрограмма и модифицирует некоторое разделяемое состояние, так что первая программа после возобновления столкнётся в неожиданностью

**В модели однопоточной конкурентности нужно модифицировать состояние в точке await**


## Блокировки

Блокировки asyncio работают так же, как и блокировки в модулях, обеспечивающих многопоточность и многопроцессность. Главное отличие в том, что блокировки asyncio - объекты, допускающие ожидание, которые приостанавливают выполнение сопрограммы, когда заблокированы. Это значить, что если сопрограмма ожидает освобождения блокировки, то может работать другой код.

Пример
```python
import asyncio  
from asyncio import Lock  
from utils import delay  
  
  
async def a(lock: Lock):  
    print('Сопрограмма а ждёт возможности захватить блокировку')  
    async with lock:  
        print('Сопрограмма a находится в крит секции')  
        await delay(2)  
    print('Сопрограмма а освободила блокировку')  
  
  
async def b(lock: Lock):  
    print('Сопрограмма b ждёт возможности захватить блокировку')  
    async with lock:  
        print('Сопрограмма b находится в крит секции')  
        await delay(2)  
    print('Сопрограмма b освободила блокировку')  
  
async def main():  
    lock = Lock()  
    await asyncio.gather(a(lock), b(lock))  
  
asyncio.run(main())
```

Вместо async with можно было бы использовать
```python
await lock.acquire()
try:
	...
finally:
	lock.release()
```

Но лучше использовать контекстный менеджер везде, где это только возможно.

Может показаться, что лучше сделать блокировку глобальной переменной, а не передавать в каждую функцию. Но такой метод приведёт к ошибке о наличии нескольких циклов событий

```bash
Task <Task pending name='Task-3' coro=<b()> got Future <Future pending>
```

Почему так? У большинства объектов в asyncio есть факультативный параметр loop, который позволяет указать, в каком цикле событий объект работает.

Если этот параметр не задан, то asyncio пытается получить текущий цикл событий, а если такого нет, то создаст новый.

В нашем случае создание Lock приводит к созданию нового цикла событий. Затем asyncio.run(main()) создаст ещё один цикл событийm и при попытке блокировки два разных цикла событий вступают в конфликт, что влечёт крах.

Пример с блокировками из листинга выше
```python
import asyncio  
from asyncio import Lock  
  
  
class MockSocket:  
    def __init__(self):  
        self.socket_closed = False  
  
    async def send(self, msg: str):  
        if self.socket_closed:  
            raise Exception('Сокет закрыт')  
  
        print(f'Отправляется: {msg}')  
        await asyncio.sleep(1)  
        print(f'Отправлено: {msg}')  
  
    def close(self):  
        self.socket_closed = True  
  
  
user_name_to_sockets = {  
    'John': MockSocket(),  
    'Terry': MockSocket(),  
    'Graham': MockSocket(),  
    'Eric': MockSocket()  
}  
  
  
async def user_disconnect(username: str, user_lock: Lock):  
    print(f'{username} отключен')  
    async with user_lock:  
        print(f'{username} удаляется из словаря!')  
        socket = user_name_to_sockets.pop(username)  
        socket.close()  
  
  
async def message_all_users(user_lock: Lock):  
    print('Создаются задачи отправки сообщений')  
    async with user_lock:  
        messages = [  
            socket.send(f'Привет, {user}')  
            for user, socket in user_name_to_sockets.items()  
        ]        await asyncio.gather(*messages)  
  
  
async def main():  
    user_lock = Lock()  
    await asyncio.gather(message_all_users(user_lock), user_disconnect('Eric', user_lock))  
  
  
asyncio.run(main())
```


## Ограничение уровня конкурентности на уровне семафоров

Семафор - похож на блокировку в том смысле, что его можно захватывать и освобождать, а основное отличие в том, что **семафор можно захватить не один раз, а несколько - максимальное число задаём сами.**

Под капотом семафор следит за этим пределом, при каждом захвате предел уменьшается, а при каждом освобождении увеличивается. Как только счётчик обращается в нуль, дальнейшие попытки захватить семафор блокируются, пока кто-то не выполнит операцию освобождения, которая увеличит счётчик.

Пример
```python
import asyncio  
from asyncio import Semaphore  
  
  
async def operation(semaphore: Semaphore):  
    print('Жду возможности захватить семафор...')  
    async with semaphore:  
        print('Семафор захвачен')  
        await asyncio.sleep(2)  
    print('Семафор освобождён')  
  
  
async def main():  
    semaphore = Semaphore(2)  
    await asyncio.gather(*[operation(semaphore) for _ in range(4)])  
  
  
asyncio.run(main())
```

При выполнении получим примерно такую картину

```
Жду возможности захватить семафор...
Семафор захвачен
Жду возможности захватить семафор...
Семафор захвачен
Жду возможности захватить семафор...
Жду возможности захватить семафор...
Семафор освобождён
Семафор освобождён
Семафор захвачен
Семафор захвачен
Семафор освобождён
Семафор освобождён
```

Поскольку семафор допускает только два захвата перед блокировкой, первые две задачи благополучно захватят его, а две оставшиеся должны будут ждать освобождения семафора.

Более реалистичный пример с ограничением количества http запросов
```python
import asyncio  
from asyncio import Semaphore  
from aiohttp import ClientSession  
  
  
async def get_url(  
        url: str,  
        session: ClientSession,  
        semaphore: Semaphore  
):  
    print('Жду возможности захватить семафор')  
    async with semaphore:  
        print('Семафор захвачен. Отправляю запрос.')  
        response = await session.get(url)  
        print('Запрос завершён')  
  
    return response.status  
  
  
async def main():  
    semaphore = Semaphore(10)  
    async with ClientSession() as session:  
        tasks = [  
            get_url('https://www.example.com', session, semaphore)  
            for _ in range(1000)  
        ]  
        await asyncio.gather(*tasks)  
  
asyncio.run(main())
```

После каждого завершения запроса семафор освобождается, а значит задача, заблокированная в ожидании семафора, может приступить к работе. То есть в каждый момент времени активно будет не более 10 запросов.

Это решает проблему слишком большого числа конкурентных запросов, но теперь код демонстрирует пульсирующую нагрузку, т.е. запросы могут отправляться пачками по 10, создавая пики трафика.


### Ограниченные семафоры

Одна из особенностей семафоров заключается в том, что число вызовов метода release может превышать число вызовов acquire. Если мы всегда используем семафоры в сочетании с блоком async with, то такое невозможно. Но если требуется более точный контроль над механизмом захвата и освобождения, то возможны проблемы.

Пример
```python
import asyncio  
from asyncio import Semaphore  
  
  
async def acquire(semaphore: Semaphore):  
    print('Ожидание возможности захвата')  
    async with semaphore:  
        print('Захвачен')  
        await asyncio.sleep(5)  
    print('Освобождается')  
  
  
async def release(semaphore: Semaphore):  
    print('Одиночное освобождение!')  
    semaphore.release()  
    print('Одиночное освобождение - готово!')  
  
  
async def main():  
    semaphore = Semaphore(2)  
  
    print('Два захвата, три освобождения...')  
    await asyncio.gather(  
        acquire(semaphore),  
        acquire(semaphore),  
        release(semaphore)  
    )  
  
    print('Три захвата...')  
    await asyncio.gather(  
        acquire(semaphore),  
        acquire(semaphore),  
        acquire(semaphore)  
    )  
  
  
asyncio.run(main())
```


Здесь мы два раза вызываем acquire (захватывает и освобождает в нашем случае) и один раз делаем одиночное освобождение, то есть освобождаем трижды.

Первый gather отрабатывает нормально
```
Два захвата, три освобождения...
Ожидание возможности захвата
Захвачен
Ожидание возможности захвата
Захвачен
Одиночное освобождение!
Одиночное освобождение - готово!
Освобождается
Освобождается
```

Однако во втором gather семафор захватывается трижды. Таким образом мы непреднамеренно превысили предел семафора
```
Три захвата...
Ожидание возможности захвата
Захвачен
Ожидание возможности захвата
Захвачен
Ожидание возможности захвата
Захвачен
Освобождается
Освобождается
Освобождается
```

Для таких ситуаций asyncio предлагает класс BoundedSemaphore. Ведёт он себя так же, как обычный, с одним отличием: при попытке вызвать метод release таким образом, что это изменит допустимый предел захватов, возбуждается исключение ValueError.

```python
import asyncio  
from asyncio import BoundedSemaphore  
  
  
async def main():  
   semaphore = BoundedSemaphore(1)  
  
   await semaphore.acquire()  
   semaphore.release()  
   semaphore.release()  
  
  
asyncio.run(main())
```


**Если acquire и release вызываются вручную, то стоит использовать BoundedSemaphore, в случае использования async with - обычный Semaphore**


## Уведомление задач с помощью событий

Иногда необходимо дождаться какого-то внешнего события, прежде, чем продолжить работу. Для этого существует Event - механизм, позволяющий ждать ничего не делая, пока что-то произойдёт.

В классе Event есть:
* сопрограмма wait - будучи помощёная в await она блокирует выполнение, пока не произойдёт set.
* set - устанавливает флаг в True и уведомляет всех, кто ждёт события
* clear - сбрасывает флаг в False - в результате любой объект, ожидающий события, будет блокирующий

Если вызвать clear после set, то обращения к wait снова начнут блокироваться до момента очередного вызова set.

Пример
```python
import asyncio  
import functools  
from asyncio import Event  
  
  
def trigger_event(event: Event):  
    print('Активируется событие!')  
    event.set()  
  
  
async def do_work_on_event(event: Event):  
    print('Ожидаю события')  
    # Ждать события  
    await event.wait()  
    print('Работаю')  
    # Когда событие произойдёт, блокировка снимается и мы можем начать работу  
    await asyncio.sleep(1)  
    print('Работа закончена')  
    # Сбросить событие, в результате чего последующие обращения к wait блокируются  
    event.clear()  
  
async def main():  
    event = Event()  
    asyncio.get_running_loop().call_later(  
        3.0,  
        functools.partial(trigger_event, event)  
    )  
    await asyncio.gather(do_work_on_event(event), do_work_on_event(event))  
  
asyncio.run(main())

```

Вывод
```
Ожидаю события
Ожидаю события
Активируется событие!
Работаю
Работаю
Работа закончена
Работа закончена
```

Это основной способ применения: ожидание события блокирует одну или несколько сопрограмм, пока событие не произойдёт, после чего они могут продолжить работу.

Более сложный  пример. Допустим мы делаем API для загрузки файлов на сервер. Мы хотим, чтобы в составе API была сопрограмма, которая блокируется до полного завершения загрузки. Вызывающая эту сопрограмму сторона должна будет дождаться прихода данных, а потом сможет работать с ними.

```python
import asyncio  
from asyncio import StreamReader, StreamWriter  
  
  
class FileUpload:  
    def __init__(self, reader: StreamReader, writer: StreamWriter):  
        self._reader = reader  
        self._writer = writer  
        self._finshed_event = asyncio.Event()  
        self._buffer = b''  
        self._upload_task = None  
  
    def listen_for_uploads(self):  
        self._upload_task = asyncio.create_task(self._accept_upload())  
  
    async def _accept_upload(self):  
        while data := await self._reader.read(1024):  
            self._buffer += data  
  
        self._finshed_event.set()  
        self._writer.close()  
        await self._writer.wait_closed()  
  
    async def get_contents(self):  
        await self._finshed_event.wait()  
        return self._buffer
```

Теперь  создадим сервер загрузки файлов для тестирования. 

```python
import asyncio  
from asyncio import StreamReader, StreamWriter  
from chapter_11.listing_11_11 import FileUpload  
  
  
class FileServer:  
    def __init__(self, host, port):  
        self.host = host  
        self.port = port  
        self.upload_event = asyncio.Event()  
  
    async def start_server(self):  
        server = await asyncio.start_server(  
            self._client_connected,  
            self.host,  
            self.port  
        )  
        await server.serve_forever()  
  
    async def dump_contents_on_complete(self, upload: FileUpload):  
        file_contents = await upload.get_contents()  
        print(file_contents)
  
    async def _client_connected(
	    self, reader: StreamReader, writer: StreamWriter
	):  
        upload = FileUpload(reader, writer)  
        upload.listen_for_uploads()  
        asyncio.create_task(self.dump_contents_on_complete(upload))  
  
  
async def main():  
    server = FileServer('127.0.0.1', 9000)  
    await server.start_server()  
  
asyncio.run(main())
```


У событий есть один недостаток. Если события срабатывают чаще, чем сопрограммы успевают их обработать, то мы никогда не увидим, что событие сработало

Пример
```python
import asyncio  
from asyncio import Event  
from contextlib import suppress  
  
  
async def trigger_event_periodically(event: Event):  
    while True:  
        print('Активируется событие')  
        event.set()  
        await asyncio.sleep(1)  
  
  
async def do_work_on_event(event: Event):  
    while True:  
        print('Ожидаю события')  
        await event.wait()  
        event.clear()  
        print('Работаю')  
        await asyncio.sleep(5)  
        print('Работа закончена!')  
  
  
async def main():  
    event = asyncio.Event()  
  
    trigger = asyncio.wait_for(trigger_event_periodically(event), 5.0)  
  
    with suppress(asyncio.TimeoutError):  
        await asyncio.gather(do_work_on_event(event), do_work_on_event(event))  
  
  
asyncio.run(main())
```


Продолжая генерировать события тут мы не увидим обработки всех вызванных (так как задачи выполняются долго).

События полезны для уведомления о том, что произошло что-либо, но что если нам нужно сочетать ожидание события с монопольным доступом к разделяемому ресурсу? Тога могут помочь условия


## Условия

Допустим, что по событию требуется получить доступ к разделяемому ресурсу, т.е. захватить блокировку. Или что перед продолжением работы нужно дождаться более сложного сочетания условий, чем простое событие. 
Или что нужно разбудить не все задачи, а только определённое число всех встречавшихся до сих пор примитивов синхронизации.

Во всех случаях может помочь Условие.

Условие объединяет в себе некоторые аспекты блокировки и события. Сначала мы захватываем блокировку (что даёт монопольный доступ к разделяемому ресурсу), а затем мы ждём события с помощью wait или wait_for. Эти сопрограммы освобождают блокировку и блокируют выполнение до возникновения события, после чего заново захватывают блокировку, восстанавливая монопольный доступ.

Пример
```python
import asyncio  
from asyncio import Condition  
  
  
async def do_work(condition: Condition):  
    while True:  
        print('Ожидаю блокировки условия...')  
        # Ждём возможности захватить блокировку условия;  
        # после захвата освободить блокировку        async with condition:  
            print('Блокировка захвачена, освобождаю. и жду выполнения условий')  
            # Ждать события. Когда произойдёт снова захватить блокировку  
            await condition.wait()  
            print('Условие выполнено, вновь захватываю блокировку и начинаю работать...')  
            await asyncio.sleep(1)  
        print('Работа закончена. Блокировка освобождена.')  
  
  
async def fire_event(condition: Condition):  
    while True:  
        await asyncio.sleep(5)  
        print('Перед уведомлением захватываю блокировку условия...')  
        async with condition:  
            print('Блокировка захвачена, уведомляю всех исполнителей')  
            # Уведомить все задачи о событии  
            condition.notify_all()  
  
  
async def main():  
    condition = Condition()  
  
    asyncio.create_task(fire_event(condition))  
    await asyncio.gather(do_work(condition), do_work(condition))  
  
asyncio.run(main())
```

**Здесь 2 корутины: do_work и fire_event. do_work захватывает условие, что аналогично захвату блокировки, а затем вызывает метод wait. Этот метод блокирует выполнение, пока кто-то не вызовет метод условия notify_all.**
**Сопрограмма fire_event некоторое время спит, а затем захватывает условие и вызывает метод notify_all, который пробуждает все задачи,  в данный момент ожидающие условия.**

Вывод
```
Ожидаю блокировки условия...
Блокировка захвачена, освобождаю. и жду выполнения условий
Ожидаю блокировки условия...
Блокировка захвачена, освобождаю. и жду выполнения условий
Перед уведомлением захватываю блокировку условия...
Блокировка захвачена, уведомляю всех исполнителей
Условие выполнено, вновь захватываю блокировку и начинаю работать...
Работа закончена. Блокировка освобождена.
Ожидаю блокировки условия...
Условие выполнено, вновь захватываю блокировку и начинаю работать...
Работа закончена. Блокировка освобождена.
Ожидаю блокировки условия...
Блокировка захвачена, освобождаю. и жду выполнения условий
Блокировка захвачена, освобождаю. и жду выполнения условий
Перед уведомлением захватываю блокировку условия...
Блокировка захвачена, уведомляю всех исполнителей
Условие выполнено, вновь захватываю блокировку и начинаю работать...
Работа закончена. Блокировка освобождена.
Ожидаю блокировки условия...
Условие выполнено, вновь захватываю блокировку и начинаю работать...
Работа закончена. Блокировка освобождена.
Ожидаю блокировки условия...
Блокировка захвачена, освобождаю. и жду выполнения условий
Блокировка захвачена, освобождаю. и жду выполнения условий
...
```

Обратите внимание, что оба исполнителя начинают работать немедленно и блокируются, ожидая, пока сопрограмма fire_event вызовет notify_all. После этого задачи-исполнители пробуждаются и продолжают делать своё дело.

У условий есть дополнительный метод wait_for, он принимает предикант (функция возвращающая булево значение) и блокирует выполнение, пока предикант не примет значение равное True. Это полезно когда есть разделяемый ресурс и сопрограммы, выполнение которых зависит от того, когда некоторое условие, определяемое состоянием ресурса станет истинным.

Пример
```python
import asyncio  
from enum import Enum  
  
  
class ConnectionState(Enum):  
    WAIT_INIT = 0  
    INITIALIZING = 1  
    INITIALIZED = 2  
  
  
class Connection:  
    def __init__(self):  
        self._state = ConnectionState.WAIT_INIT  
        self._condition = asyncio.Condition()  
  
    async def initialize(self):  
        await self._change_state(ConnectionState.INITIALIZING)  
        print('initialize: Инициализация подключения...')  
        # Имитация времени подключения  
        await asyncio.sleep(3)  
        print('initialize: Подключение инициализировано')  
        await self._change_state(ConnectionState.INITIALIZED)  
  
    async def execute(self, query:str):  
        async with self._condition:  
            print('execute: Ожидание инициализации подключения.')  
            await self._condition.wait_for(self._is_initialized)  
            print(f'execute: Выполняется {query}!!!')  
            await asyncio.sleep(3)  
  
    async def _change_state(self, state: ConnectionState):  
        async with self._condition:  
            print(f'change_state: Состояние изменяется с {self._state} на {state}')  
            self._state = state  
            self._condition.notify_all()  
  
    def _is_initialized(self):  
        if self._state is not ConnectionState.INITIALIZED:  
            print(f'_is_initialized: Инициализация подключения не закончена, состояние равно {self._state}')  
            return False  
  
        print('_is_initialized: Подключение инициализировано!')  
        return True  
  
async def main():  
    connection = Connection()  
    query_one = asyncio.create_task(connection.execute('select * from table'))  
    query_two = asyncio.create_task(connection.execute('select * from other_table'))  
    asyncio.create_task(connection.initialize())  
  
    await query_one  
    await query_two  
  
  
asyncio.run(main())
```

Вывод
```
execute: Ожидание инициализации подключения.
_is_initialized: Инициализация подключения не закончена, состояние равно ConnectionState.WAIT_INIT
execute: Ожидание инициализации подключения.
_is_initialized: Инициализация подключения не закончена, состояние равно ConnectionState.WAIT_INIT
change_state: Состояние изменяется с ConnectionState.WAIT_INIT на ConnectionState.INITIALIZING
initialize: Инициализация подключения...
_is_initialized: Инициализация подключения не закончена, состояние равно ConnectionState.INITIALIZING
_is_initialized: Инициализация подключения не закончена, состояние равно ConnectionState.INITIALIZING
initialize: Подключение инициализировано
change_state: Состояние изменяется с ConnectionState.INITIALIZING на ConnectionState.INITIALIZED
_is_initialized: Подключение инициализировано!
execute: Выполняется select * from table!!!
_is_initialized: Подключение инициализировано!
execute: Выполняется select * from other_table!!!
```

Условия в целом полезны тогда, когда необходим доступ к разделяемому ресурсу, и перед началом работы требуется получить уведомление о некотором состоянии.

