Вопросы
* Выполнение совместимых с asyncio запросов к базе данных с помощью asyncpg
* Создание пула подключений к базе данных для конкурентного выполнения нескольких SQL-запросов
* Управление асинхронными транзакциями БД
* Использование асинхронных генераторов для потоковой обработки результата запроса


Как в случае веб-запросов, нам понадобится совместимая с asyncio библиотека, потому что большинство стандартных библиотек для работы с SQL блокируют главный поток, а значит, цикл событий до получения результата.

**Внимание**
Здесь говорится исключительно о PostgreSQL и использовать asyncpg.
**asyncpg** - библиотека, которая позволяет асинхронно подключаться к БД и не блокирует сокеты.

## Подключение к БД Postgres

Для работы с asyncpg разберёи пример с БД с информацией о товарах из интернет магазина.

Пример подключения:
```python
# Подключение к базе данных Postgres
import asyncio
import asyncpg


async def main():
	connection = await asyncpg.connect(
		host='127.0.0.1',
		port=5432,
		user='ishimura',
		database='asyncio_eshop',
		password='1111'
	)
	
	version = connection.get_server_version()
	print(version)
	
	await connection.close()


asyncio.run(main())
```


## Определение схемы БД

Таблицы (название БД asycnio_eshop):
* Марка
	Под маркой (brand) понимается производитель многих различных товаров.

* Товар
	Товар (product) ассоциирован с одной макрой, существует связь один-к-одному между марками и товарами. Для простоты в нашей БД у товара будет только название. Кроме того с каждый товаром может быть связанно несколько размеров и цветов.

* SKU
	SKU - stock keeping unit (складская единица хранения). SKU представляет конкретный предмет, выставленный на продажу. 

* Размер товара
	Товар может иметь несколько размеров (product_size).

* Цвет товара
	Товар может иметь несколько цветов.

![[Pasted image 20250129151402.png]]

### Команды для создания таблиц 
```python
# Команды создания таблиц и вставки данных

CREATE_BRAND_TABLE = \

"""

CREATE TABLE IF NOT EXISTS brand (

brand_id SERIAL PRIMARY KEY,

brand_name TEXT NOT NULL

);

"""

  

CREATE_PRODUCT_TABLE = \

"""

CREATE TABLE IF NOT EXISTS product (

product_id SERIAL PRIMARY KEY,

product_name TEXT NOT NULL,

brand_id INT NOT NULL,

FOREIGN KEY (brand_id) REFERENCES brand(brand_id)

);

"""

  

CREATE_PRODUCT_COLOR_TABLE = \

"""

CREATE TABLE IF NOT EXISTS product_color (

product_color_id SERIAL PRIMARY KEY,

product_color_name TEXT NOT NULL

);

"""

  

CREATE_PRODUCT_SIZE_TABLE = \

"""

CREATE TABLE IF NOT EXISTS product_size (

product_size_id SERIAL PRIMARY KEY,

product_size_name TEXT NOT NULL

);

"""

  

CREATE_SKU_TABLE = \

"""

CREATE TABLE IF NOT EXISTS sku (

sku_id SERIAL PRIMARY KEY,

product_id INT NOT NULL,

product_size_id INT NOT NULL,

product_color_id INT NOT NULL,

FOREIGN KEY (product_id)

REFERENCES product(product_id),

FOREIGN KEY (product_size_id)

REFERENCES product_size(product_size_id),

FOREIGN KEY (product_color_id)

REFERENCES product_color(product_color_id)

);

"""

  

COLOR_INSERT = \

"""

INSERT INTO product_color VALUES(1, 'Blue');

INSERT INTO product_color VALUES(2, 'Black');

"""

  

SIZE_INSERT = \

"""

INSERT INTO product_size VALUES(1, 'Small');

INSERT INTO product_size VALUES(2, 'Medium');

INSERT INTO product_size VALUES(3, 'Large');

"""
```

## Выполнение запросов с помощью asyncpg

Чтобы выполнить запрос к БД, нужно сначала подключиться к экземпляру Postgres и создать БД.

Создав БД подключимся к ней и выполним команды create. В классе connection имеется сопрограмма execite, которая позволяет выполнить команды одну за другой. Эта сопрограмма возвращает полученную от Postgres строку, представляющую состояние запроса.

Пример
```python
# Использование сопрограммы execute для выполнение команд create
import asyncio
import asyncpg
from listing_5_2 import CREATE_BRAND_TABLE, CREATE_PRODUCT_COLOR_TABLE,\
	CREATE_PRODUCT_SIZE_TABLE, CREATE_PRODUCT_TABLE, CREATE_SKU_TABLE,\
	SIZE_INSERT, COLOR_INSERT


async def main():
	connection = await asyncpg.connect(
		host='127.0.0.1',
		port=5432,
		user='ishimura',
		database='asyncio_eshop',
		password='1111'
	)

	statements = [
		CREATE_BRAND_TABLE,
		CREATE_PRODUCT_COLOR_TABLE,
		CREATE_PRODUCT_SIZE_TABLE,
		CREATE_PRODUCT_TABLE,
		CREATE_SKU_TABLE,
		SIZE_INSERT,		
		COLOR_INSERT
	]
	
	print('Создаётся база данных')
	
	for statement in statements:
		status = await connection.execute(statement)
		print(status)
		
	print('База данных создана!')
	await connection.close()


asyncio.run(main())
```

Отметим, что execute - сопрограмма, поэтому завершения команд стоит ждать при помощи await. В конце мы закрываем подключение к БД. 

**Примечание**
Поскольку одни таблицы зависят от других, мы не можем выполнять эти команды конкурентно.


Вставим несколько марок, а затем выполним запрос и убедимся, что вставка прошла нормально. Для вставки данных можно использовать всё ту же сопрограмму execute, а для выборки - сопрограмму fetch.

```python
# Вставка и выборка марок
import asyncio
import asyncpg
from asyncpg import Record
from typing import List


async def main():
	connection = await asyncpg.connect(
		host='127.0.0.1',
		port=5432,
		user='ishimura',
		database='asyncio_eshop',
		password='1111'
	)

	await connection.execute("INSERT INTO brand VALUES(DEFAULT, 'Levis')")
	await connection.execute("INSERT INTO brand VALUES(DEFAULT, 'Seven')")

	brand_query = 'SELECT brand_id, brand_name FROM brand'
	results: List[Record] = await connection.fetch(brand_query)

	for brand in results:
		print(f'id: {brand["brand_id"]}, name: {brand["brand_name"]}')
	
	await connection.close()

asyncio.run(main())
```

По завершении запроса результаты будут находится в памяти, в переменной results. Каждый запрос представлен объектом asyncpg Record. Эти объекты похожи на словари: они позволяют обращаться к данным, передавая имя столбца в качестве индекса. 

В этом примере все возвращённые запросом данные помещены в список. Если бы мы хотели выбрать одну запись, то вызвали бы функцию connection.fetchrow(). По умолчанию все результаты запроса загружается в память, поэтому пока нет разницы в производительности между fetchrow и fetch.


## Конкурентное выполнение запросов с помощью пулов подключений

Для демонстрации предположим, что мы управляем успешным интернет-магазином. У нас есть 100 00 SKU от 1000 различных марок.

### Вставка случайных SKU в БД

Сгенерируем их случайным образом, выберем названия из списка 1000 самых часто встречающихся английских слов.

Первым делом вставим марки. Воспользуемся connection.executemany, которая выполняет параметризированую SQL-команду и позволит нам написать один запрос и передавать ему список вставляемых записей в виде параметров.

executemany принимает одну SQL-команду и список кортежей, содержащих вставляемые значения. Параметры представлены маркерами $1, $2 ..., $N. Число после знака доллара равно индексу элемента кортежа. 

Пример
```python
# Вставка случайных марок
import asyncpg
import asyncio
from typing import List, Tuple, Union
from random import sample

def load_common_words() -> List[str]:
	with open('Примеры кода (Python)/py_async/fauler/chapter_5/common_words.txt') as common_words:
		return common_words.readlines()


def generate_brand_names(words: List[str]) -> List[Tuple[Union[str, ]]]:
	return [(words[index],) for index in sample(range(100), 100)]


async def insert_brands(common_words, connection) -> int:
	brands = generate_brand_names(common_words)
	insert_brands = "INSERT INTO brand VALUES(DEFAULT, $1)"

	return await connection.executemany(insert_brands, brands)

  
  

async def main():
	common_words = load_common_words()

	connection = await asyncpg.connect(
		host='127.0.0.1',
		port=5432,
		user='ishimura',
		database='asyncio_eshop',
		password='1111'
	)

	await insert_brands(common_words, connection)  

asyncio.run(main())
```

За кулисами executemany в цикле обходит список марок и генерирует по одной команде INSERT для каждой марки. Затем она выполняет сразу все эти команды. Заодно этот метод защищает от SQL инъекций, т.к. данные экранируются.

Также вставим случайные товары и SKU
```python
import asyncio
import asyncpg
from random import randint, sample
from typing import List, Tuple
from listing_5_5 import load_common_words


def gen_products(
	common_words: List[str],
	brand_id_start: int,
	brand_id_end: int,
	products_to_create: int
) -> List[Tuple[str, int]]:
	products = []
	
	for _ in range(products_to_create):
		description = [common_words[index] for index in sample(range(100), 100)]
		brand_id = randint(brand_id_start, brand_id_end)
		products.append((" ".join(description), brand_id))
	
	return products


def gen_skus(
	product_start_id: int, product_end_id: int, skus_to_create: int
) -> List[Tuple[int, int, int]]:
	skus = []

	for _ in range(skus_to_create):
		product_id = randint(product_start_id, product_end_id)
		size_id = randint(1, 3)
		color_id = randint(1, 2)

		skus.append((product_id, size_id, color_id))

	return skus


async def main():
	common_words = load_common_words()
	connection = await asyncpg.connect(
		host='127.0.0.1',
		port=5432,
		user='ishimura',
		database='asyncio_eshop',
		password='1111'
	)

	product_tuples = gen_products(
		common_words,
		brand_id_start=1,
		brand_id_end=100,
		products_to_create=1000
	)

	await connection.executemany(
		"INSERT INTO product VALUES(DEFAULT, $1, $2)", product_tuples
	)

	sku_tuples = gen_skus(
		product_start_id=1,
		product_end_id=100,
		skus_to_create=1000
	)

	await connection.executemany(
		"INSERT INTO sku VALUES(DEFAULT, $1, $2, $3)", sku_tuples
	)

	await connection.close()

asyncio.run(main())
```

В предложении, что в каждый момент времени запрашивается информация о многих товарах, этот запрос является прекрасным кандидатом для конкурентности. Можно наивно применить gather для нескольких запросов, но он выдаст ошибку.

**В SQL одному подключению к БД соответсвует один сокет. Поскльку подключение всего одно, а мы пытаемся прочитать одновременно результаты сразу нескольких запрооов.**

Проблема решается создав несколько подключений. Однако их создание обходится дорого, поэтому имеет смысл кешировать их и получать их кеша по мере необходимостию. Обычно такой кеш называется **пулом подключений**.

### Создание пула подключений для конкурентного выполнения запросов

Поскольку в один момент времени на одном подключении можно выполнить только один запрос, нам необходим механизм для создания нескольких подключений и управления ими. Именно этот механизм называется **пулом подключений**.
В пуле находится конечное число подключений, которые можно **захватывать** по мере необходимости.

Пулы обеспечивают повторное использование подключений. Т.е. мы захватываем подключение, выполняем запрос, после выполнение подключение освобождается (возвращается обратно в пул). Это важно, т.к. создание подключения к БД - дорогая операция.

Т.к. число подключений в пуле конечно, то придётся немного подождать освобождения подключения, если все они заняты. 
Поэтому операция захвата подключений может занять некоторое время.

Допустим у нас есть пул с двумя подключениями, две сопрограммы захватили подключения, тогда третьей сопрограмма придётся подождать свободного подключения. После она захватит его и начнёт выполнять запрос.

![[Pasted image 20250129155500.png]]

Для создания пула подключений asycnio предлагает сопрограмму create_pool. При вызове мы будем указывать минимальное число подключенний (min_size, гарантируется, что такое кол-во подключений будет всегда) и максимальное число подключений (max_size, если подключений недостаточно,то  создадутся дополнительные, но они не должны превышать max_size).

**Пулы в asyncpg являются асинхронными контекстными менеджерами, т.е. для создания пула нужно использовать конструкцию async with**. **Подключение захватывается при помощи сопрограммы acquire. Захват соединения также является асинхронным контекстным менеджером, который возвращает соединение в пулл после использования.**

Пример
```python
# Создание пула подключений и конкурентное выполнение запросов
import asyncio
import asyncpg


product_query = \
"""
	SELECT
	
	p.product_id,
	
	p.product_name,
	
	p.brand_id,
	
	s.sku_id,
	
	pc.product_color_name,
	
	ps.product_size_name
	
	FROM product p
	
	JOIN sku s ON s.product_id = p.product_id
	
	JOIN product_color pc ON pc.product_color_id = s.product_color_id
	
	JOIN product_size ps ON ps.product_size_id = s.product_size_id
	
	WHERE p.product_id = 100;
"""

  
  

async def query_product(pool):
	async with pool.acquire() as conn:
		return await conn.fetchrow(product_query)

  
  

async def main():
	async with asyncpg.create_pool(
		host='127.0.0.1',
		port=5432,
		user='ishimura',
		password='1111',
		database='asyncio_eshop',
		min_size=6,
		max_size=6
	) as pool: # создать пул с 6 подключениями

		# Конкурентно выполнить запросы		
		await asyncio.gather(query_product(pool), query_product(pool))

  

asyncio.run(main())
```

Также сравним время выполнение с синхронной версией
```python
import asyncio
import asyncpg
from utils import async_timed

product_query = \
	"""
	
	SELECT
	
	p.product_id,
	
	p.product_name,
	
	p.brand_id,
	
	s.sku_id,
	
	pc.product_color_name,
	
	ps.product_size_name
	
	FROM product p
	
	JOIN sku s ON s.product_id = p.product_id
	
	JOIN product_color pc ON pc.product_color_id = s.product_color_id
	
	JOIN product_size ps ON ps.product_size_id = s.product_size_id
	
	WHERE p.product_id = 100;
	
	"""

  
  

async def query_product(pool):
	async with pool.acquire() as connection:
		return await connection.fetchrow(product_query)

  
  

@async_timed()
async def query_products_synchronously(pool, queries):
	return [await query_product(pool) for _ in range(queries)]

  
  

@async_timed()
async def query_product_concurrently(pool, queries):
	queries = [query_product(pool) for _ in range(queries)]
	return await asyncio.gather(*queries)

  
  

async def main():
	async with asyncpg.create_pool(
		host="127.0.0.1",
		port=5432,
		user="ishimura",
		password="1111",
		database="asyncio_eshop",
		min_size=6,
		max_size=6
	) as pool:

		await query_products_synchronously(pool, 10000)
		await query_product_concurrently(pool, 10000)

asyncio.run(main())
```

Вывод
```bash
Выполняется функия <function query_products_synchronously at 0x71ce2aea4dc0> с аргументами (<asyncpg.pool.Pool object at 0x71ce2b1ed840>, 10000) {}
<function query_products_synchronously at 0x71ce2aea4dc0> завершилась за 7.2302 c.

Выполняется функия <function query_product_concurrently at 0x71ce2aea4ee0> с аргументами (<asyncpg.pool.Pool object at 0x71ce2b1ed840>, 10000) {}
<function query_product_concurrently at 0x71ce2aea4ee0> завершилась за 4.2496 c.
```

## Управление транзакциями в asycnpg

Транзакции - ключевая концепция во многих БД, обладающих свойством ACID (атомарность, согласованность, изолированность, долговечность). 

Транзакция включает в себя одну или несколько команд, выполняемых как неделимое целое. Если при выполнении этих команд не было ошибок, до транзакция фиксируется в БД, так что изменения становятся постоянными. Если же ошибка была, то транзакция откатывается и БД выглядит так, будто ни одна из команд не выполнялась.

**В asyncpg для работы с транзакциями проще всего воспользоваться асинхронным контекстным менеджером connection.transaction, который начинает транзакцию, а затем, если в блоке async with произойдёт ошибка, автоматически откатывает её. Если же все команды успешны, то транзакцию автоматически фиксируется.**

Пример создания транзакции
```python
# Создание транзакции
import asyncio
import asyncpg


async def main():
	connection = await asyncpg.connect(
		host="127.0.0.1",
		port=5432,
		user="ishimura",
		database="asyncio_eshop",
		password="1111"
	)
	# Начать транзакцию БД
	async with connection.transaction():
		await connection.execute("INSERT INTO brand VALUES(DEFAULT, 'brand_1')")
		await connection.execute("INSERT INTO brand VALUES(DEFAULT, 'brand_2')")

  

	query = """
		
		SELECT brand_name
		
		FROM brand
		
		WHERE brand_name LIKE 'brand%'
	
	"""
	# Выбрать марки и убедиться, что транзакция была зафиксирована
	brands = await connection.fetch(query)
	print(brands)  
	
	await connection.close()

asyncio.run(main())
```


Пример обработки ошибок в транзакции
```python
# Обработки ошибки
import asyncio
import logging
import asyncpg


async def main():
	connection = await asyncpg.connect(
		host="127.0.0.1",
		port=5432,
		user="ishimura",
		database="asyncio_eshop",
		password="1111"
	)

	try:
		async with connection.transaction():
		insert_brand = "INSERT INTO brand VALUES(9999, 'big_brand')"
		
		await connection.execute(insert_brand)
		# Команда завершится неудачно из-за дубликата PK
		await connection.execute(insert_brand)
	
	except Exception:
		logging.exception("Ошибка при выполнении транзакции")
	
	finally:
		query = """
			SELECT brand_name
			FROM brand
			WHERE brand_name LIKE 'big_%'
		"""
		# Выбрать марки и убедится, что вставки не было
		brands = await connection.fetch(query)
		print(f'Результат запроса: {brands}')
		
		await connection.close()  

asyncio.run(main())
```

### Вложенные транзакции

asyncpg поддерживает вложенные транзакции благодаря имеющемуся в Postgres механизму точек сохранения, которые определяются командой SAVEPOINT.
Если она определена, то мы можем откатиться к ней, т.е. все запросы, выполненные после точки откатываются.

**Для создания точки сохранения вызывается контекстный менеджер connection.transaction, которому передаётся существующая транзакция. Затем, если во внутренней транзакции произошла ошибка, то он откатывается, но внешняя транзакция при этом не затрагивается.**

Пример
```python
# Вложенная транзакция
import asyncio
import asyncpg
import logging


async def main():
	connection = await asyncpg.connect(
		host="127.0.0.1",
		port=5432
		user="ishimura",
		database="asyncio_eshop",
		password="1111"
	)

	async with connection.transaction():
		await connection.execute(
			"INSERT INTO brand VALUES(DEFAULT, 'my_new_brand')"
		)

		try:
			async with connection.transaction():
				await connection.execute(
					"INSERT INTO product_color VALUES(1, 'black')"
				)
		
		except Exception as ex:		
			logging.warning('Ошибка при вставке товара')

	await connection.close()

asyncio.run(main())
```

**Первая команда выполнится успешно, потому что такой марки в БД нет. А вторая выполнится с ошибкой (дубликат ключа). Внешняя транзакция не откатывается и новая марка создаётся, а внутренняя откатывается.**

### Ручное управление транзакциями 

Ручное управление транзакциями может быть полезно, когда например нужно выполнить специальный код при откате или произвести откат по условию. 

**Для ручного управления транзакцией мы можем воспользоваться менеджером транзакций, возвращённым методом connection.transaction вне контекстного менеджера. При этом нужно вручную вызывать метод start, чтобы начать транзакцию, а затем метод commit в случае успешного завершения или rollback в случае ошибки**.

Пример
```python
# Ручное управление транзакцией
import asyncio
import asyncpg
from asyncpg.transaction import Transaction

async def main():
	connection = await asyncpg.connect(
		host="127.0.0.1",
		port=5432,
		user="ishimura",
		database="asyncio_eshop",
		password="1111"
	)

	transaction: Transaction = connection.transaction()	
	await transaction.start()

	try:
		await connection.execute("INSERT INTO brand VALUES (DEFAULT, 'brand_1')")
		await connection.execute("INSERT INTO brand VALUES (DEFAULT, 'brand_2')")
	except asyncpg.PostgresError:
		print('Ошибка, транзакция откатывается')
		# Откатить в случае исключения
		await transaction.rollback()
	else:
		print('Ошибки нет, транзакция фиксируется')
		# Если исключения не было, зафиксировать
		await transaction.commit()

  

	query = """
		SELECT brand_name
		FROM brand
		WHERE brand_name LIKE 'brand%'
	"""
	brands = await connection.fetch(query)
	print(brands)
	
	await connection.close()

asyncio.run(main())
```


## Асинхронные генераторы и потоковая обработка результирующих наборов

У реализации fetch есть недостаток - она возвращает весь результирующий набор в память. Конечно мы могли бы включить в запрос LIMIT, однако у этого есть недостаток - мы отправляем один и тот же запрос, что может создать излишнюю нагрузку на БД. 

**Поэтому иногда имеет смысл обрабатывать данные потоком. Postgres поддерживает потоковую обработку при помощи курсоров. Курсор можно рассматривать как указатель на текущую позицию в результирующем наборе. Получая один результат из потокового запроса, мы продвигаем курсор на следующую позицию, пока результаты не будут исчерпаны.**

В asyncpg получить курсор можно непосредственно от подключения, а затем использовать для потоковой обработки запроса. В реализации курсоров используется средство asyncio - **асинхронные генераторы**. Они порождают результаты асинхронно по одному, как обычные генераторы Python. Они также позволяют использовать специальный синтаксис цикла for для обхода результатов.

### Введение в асинхронные генераторы

Генератор - реализация паттерна Итератор, позволяют лениво определять последовательности данных и обходить их поэлементно. Это полезно когда последовательность велика и сохранить её в памяти целиком невозможно. Простой синхронный генератор - обычная функция, которая использует yield вместо return.

Пример
```python
# Синхронный генератор
def positive_integers(until: int):
	for integer in range(until):
		yield integer

positive_iterator = positive_integers(2)

print(next(positive_iterator))
print(next(positive_iterator))
```

Для асинхронного генератор используется конструкция **async for**

```python
import asyncio
from ..utils import async_timed, delay


async def positive_integers_async(until: int):
	for integer in range(1, until):
		await delay(integer)
		yield integer

  
@async_timed()
async def main():
	async_generator = positive_integers_async(3)
	print(type(async_generator))
	
	async for number in async_generator:
		print(f'Получено число {number}')

asyncio.run(main())
```

async_generator - объект типа <class 'async_generator'>. Отличие в том, что он отдаёт не объекты, а генеририует сопрограммы,  которые могут ждать получения результата при помощи await. Поэтому обычный for и next с ним работать не смогут. А вместо этого используется **async_for**.

## Использование асинхронных генераторов и потокового курсора

Понятие потокового курсора прекрасно сочетается с понятием асинхронного генератора. Мы можем получать по одной строке за раз в цикле, походим на for. В asyncpg для выполнения потоковой обработки сначала нужно открыть транзакцию (обязательно). Затем мы можем вызвать метод crusor класса Connection и получить курсор. Метод cursor передаётся запрос, а возвращает он асинхронный генератор для потоковой обработки результатов. 

Пример
```python
import asyncpg
import asyncio


async def main():
	connection = await asyncpg.connect(
		host="127.0.0.1",
		port=5432,
		user="ishimura",
		database="asyncio_eshop",
		password="1111"
	)

	query = "SELECT product_id, product_name FROM product"
	
	async with connection.transaction():
		async for product in connection.cursor(query):
			print(product)
	
	await connection.close()

asyncio.run(main()
```

Распечатываются все товары, хотя в память загружается лишь небольшая порция.

Объём предвыборки по умолчанию - 50 записей, но это значение можно изменить при помощи параметра perfetch.

Курсор также позволяет извлечь произвольное число записей из середины рез. набора
Пример
```python
import asyncio
import asyncpg


async def main():
	connection = await asyncpg.connect(
		host="127.0.0.1",
		port=5432,
		user="ishimura",
		database="asyncio_eshop",
		password="1111"
	)

	async with connection.transaction():
		query = "SELECT product_id, product_name FROM product"
		# Создать курсор
		cursor = await connection.cursor(query)

		# Сдвинуть курсор на 500 записей
		await cursor.forward(500)

		# Получить 100 записей
		products = await cursor.fetch(100)
		for product in products:
			print(product)

	await connection.close()

asyncio.run(main())
```

Здесь мы сначала создаём курсор для запроса. Это делается с await как для сопрограммы, а не асинхронного генератора. Это возможно, **потому что курсор одновременно объект допускающий ожидание и генератор.** В большинстве случаев оба способа похожи, но при таком создании курсора есть различия в поведении предвыборки - мы не можем задать количество выбираемых за одно обращение записей.

Получив курсор мы передвигаем его на 500 записей при помощи forward.  В результате мы пропустим первые 500 записей и получим следующие 100.


Но что если нужно выбрать фиксированное количество элементов с предвыборкой. но при этом использовать async for. Можно было бы добавить в async for счётчик, но такой подход не предусматривает повторного использования. Если такие действия производятся в сопрограмме часто, то лучше написать свой собственный асинхронный генератор, который мы назовём take. Он будет принимать асинхронный генератор и количество элементов
```python
# Получение заданного числа элементов с помошью асинх. генератора
import asyncio
import asyncpg

async def take(generator, to_take: int):
	item_count = 0
	
	async for item in generator:
		if item_count > to_take - 1:
			return
		item_count = item_count + 1
		yield item

  
  

async def main():
	connection = await asyncpg.connect(
		host="127.0.0.1",
		port=5432,
		user="ishimura",
		database="asyncio_eshop",
		password="1111"
	)

	async with connection.transaction():
		query = "SELECT product_id, product_name FROM product"
		product_generator = connection.cursor(query)

  

	async for product in take(product_generator, 5):
		print(product)

	print("Получены первые пять товаров!")
	await connection.close()  

asyncio.run(main())
```

В библиотеке aiostream с есть похожая функциональность и многое другое для работы с асинхронными генераторами

## Резюме

* Для асинхронной работы с Postgres используется asyncpg
* Пул подключений позволяет выполнять конкурентно несколько запросов и тем самым повысить скорость приложения
* Транзакции в asyncpg реализуются при помощи connection.transaction
* asynpg поддерживает вложенные транзакции при помощи механизма точек сохранения (SAVEPOINT) в Postgres
* Асинхронный генератор - генератор, который как и синхронный использует yield. Для его обхода используется async for
* Асинхронные генераторы и курсоры БД можно использовать для потоковой обработки данных (чтобы не перегружать память)