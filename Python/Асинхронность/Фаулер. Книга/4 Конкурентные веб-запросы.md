
Вопросы
* Асинхронные контекстные менеджеры
* Отправка совместимых с asyncio запросов при помощи aiohttp
* Конкурентное выполнение веб-запросов с помощью gather
* Обработка результатов по мере поступления с as completed
* Отслеживание незавершённых запросов с помощью wait
* Установка и обработка тайм-аутов для групп запросов и снятие запросов


## Введение в aiohttp и Асинхронные контекстные менеджеры

### Кратко о aiohttp
Популярная библиотека requests плохо совместима с asyncio, т.к. в ней используются блокирующие сокеты. Следовательно любая отправка запроса блокирует поток, в котором запрос отправлен, а поскольку asyncio однопоточная, будет заблокирован весь цикл событий. 

Для решения это проблемы можно использовать aiohttp, которая решает проблему блокирующих сокетов.

aiohttp - библиотека с открытым исходным кодом, часть проекта aio-libs. Она представляет собой полнофункциональный веб-сервер и веб-клиент, т.е. умеет отправлять веб-запросы и можем стать основой для асинх. веб-сервера.

### Асинхронные контекстные менеджеры

Обычные контекстные менеджеры не подходят для асинхронных задач. Для них стоит воспользоваться асинхронными контекстными менеджерами. Синтаксис - **async with.**

**Асинхронный контекстный менеджер** - класс, реализующий методы `__aenter__` (асинхронно захватывает ресурс) и `__aexit__` (закрывает ресурс). Также `__aexit__` принимает несколько аргументов, относящихся к обработке исключений.

Пример
```python
# Асинхронный контекстный менеджер, ожидающий подключения клиента

import asyncio
import socket
from types import TracebackType
from typing import Optional, Type


class ConnectedSocket:
	def __init__(self, server_socket):
		self._connection = None
		self._server_socket = server_socket

	# Вызывается при входе в блок with. Ждём подключение и возвращает его
	async def __aenter__(self):
		print('Ожидание подключения')
		loop = asyncio.get_event_loop()
		connection, address = await loop.sock_accept(self._server_socket)
		self._connection = connection
		print('Подключение подтверждено')

		return self._connection

  

	# Вызывается при выходе из блоке with. Тут производим очисту ресурса

	async def __aexit__(
		self,
		exc_type: Optional[Type[BaseException]],
		exc_val: Optional[BaseException],
		exc_tb: Optional[TracebackType]
	):
		print('Выход из контекстного менеджера')
		self._connection.close()
		print('Подключение закрыто')


async def main():
	loop = asyncio.get_event_loop()
	server_socket = socket.socket()
	server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
	server_address = ('127.0.0.1', 8000)
	server_socket.setblocking(False)
	server_socket.bind(server_address)
	server_socket.listen()

	async with ConnectedSocket(server_socket) as connection:
		data = await loop.sock_recv(connection, 1024)
		print(data)

asyncio.run(main())
```

В сопрограмме `__aenter__` мы ждём подключения клиента. Как только клиент подключился - возвращается соответствующие клиентское подключение.
Это даёт нам доступ к подключение в части as предложения async with. Затем в блоке async with мы используем это подключение для ожидания данных от клиента. Когда выполнение этого блока завершается, вызывается сопрограмма `__aexit__`, которая закрывает подключение.


### Отправка веб-запросов с помощью aiohttp

В библиотеке aiohttp и вообще при работе с веб-запросами используется понятие **сеанса**(сеанс можно рассмотреть как создание нового окна браузера).

**Внутри сеанса хранятся много открытых подключений, которые можно использовать повторно.** Это называется **пулом подключений** и играет важную роль в производительности приложений на базе aiohttp. 

**Создание подключений - дорогая операция. Следовательно наличие пула сокращает затраты на выделение и освобождение ресурсов.**

В большинстве приложений на базе aiohttp создаётся один сеанс для всего приложения. Затем объект сеанса передаётся методам. У объекта сеанса имеются методы для отправки веб-запросов. Для создания сеанса используется асинхронный контекстный менеджер **aiohttp.ClientSession**.

```python
# Отправка веб-запросов при помощи aiohttp
import asyncio
import aiohttp
from aiohttp import ClientSession

from utils import async_timed


@async_timed()
async def fetch_status(session: ClientSession, url: str) -> int:
	async with session.get(url) as result:
		return result.status
  

@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:
		url = 'https://www.example.com'
		status = await fetch_status(session, url)

		print(f"Состояние для {url} было равно {status}")

asyncio.run(main())
```

По умолчанию в сеансе ClientSession можно создавать не более 100 подключений, что даёт неявную верхнюю границу количества конкурентных веб-запросов. Чтобы изменить этот предел, можно создать экземпляр класса TCPConnector, указав максимальное число подключений, и передать его конструктору ClientSession.

### Задание тайм-аутов в aiohttp

Тайм-аут задаётся при помощи структуры данных aiohttp.ClientTimeout. Она позволяет установить не только общий тайм-аут в секундах, но также отдельные тайм-ауты для установления соединения и чтения данных.

Пример
```python
# Задание таймаутов в aiohttp
import asyncio
import aiohttp
from aiohttp import ClientSession


async def fetch_status(session: ClientSession, url: str) -> int:
	ten_millis = aiohttp.ClientTimeout(total=.01)
	async with session.get(url, timeout=ten_millis) as result:
		return result.status


async def main():
	session_timeout = aiohttp.ClientTimeout(total=1, connect=.1)
	async with aiohttp.ClientSession(timeout=session_timeout) as session:
		await fetch_status(session, 'https://www.example.com')

asyncio.run(main())
```


## И снова о конкурентном выполнении задач

Ранее несколько задач для конкурентного выполнения создавалось примерно так:
```python
# Неправильное использование спискового включения для создания и ожидания задач
import asyncio
from utils import async_timed, delay


@async_timed()
async def main() -> None:
	delay_times = [3, 3, 3]
	[await asyncio.create_task(delay(seconds)) for seconds in delay_times]

asyncio.run(main())
```

Данный код работает как синхронный, т.е. 9c. Дело в том, что мы применяли await сразу после создания задачи.

Чтобы это исправить мы можем создавать задачи в одном списковом включении, а ждать в другом. Тогда всё будет работать конкурентно.

```python
# Использование спискового включения для конкурентного выполнения задач
import asyncio
from utils import async_timed, delay


@async_timed()
async def main() -> None:
	delay_times = [3, 3, 3]
	tasks = [asyncio.create_task(delay(seconds)) for seconds in delay_times]
	[await task for task in tasks]

asyncio.run(main())
```

Однако у такого метода есть недостатки:
1. Состоит из нескольких строк (нужно не забыть отделить)
2. Негибкость (если одна из сопрограмм завершается значительно раньше, то мы застрянем во втором списковом включении, ожидая остальных сопрограмм. Иногда приемлемо, но обычно мы стремимся к большей отзывчивости)
3. Обработка исключений (если в сопрограмме возникает исключение, то оно будет возбуждено в момент ожидания сбойной задачи. Следовательно мы не можем обработать успешно завершившиеся задачи, потому что одно-единственное исключение останавливает всю работу).


## Конкурентное выполнение запросов с помощью gather

Для конкурентного выполнения допускающих ожидание объектов широко используется функция asyncio.gather(). Она принимает последовательность допускающих ожидание объектов и запускает их конкурентно всего в одной строке.

Если в объектах есть сопрограмма, то gather автоматически обертывает её задачей, чтобы гарантировать конкурентное выполнение. Следовательно не нужно обарачивать все сопрограммы по отдельности с помощью asyncio.create_task.

Если использовать его в выражении await, то выполнение будет приостановлено **пока не завершатся все переданные объекты**, а когда это произойдёт - gather вернёт список результатов работы.

Пример
```python
# Конкурентное выполнение запросов с помощью gather
import asyncio
import aiohttp
from aiohttp import ClientSession
from utils import async_timed


async def fetch_status(session: ClientSession, url: str) -> int:
	async with session.get(url) as result:
		return result.status


@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:
		urls = ['https://www.example.com' for _ in range(1000)]

		# Сгенерировать список сопрограмм для каждого запроса
		requests = [await fetch_status(session, url) for url in urls]

		# Запустить и дождаться выполнения всех запросов
		status_codes = await asyncio.gather(*requests)

		print(status_codes)

asyncio.run(main())
```

**Важно отметить**, что порядок поступления результатов не детерменирован. Например, если передать gather сопрограммы a и b именно в таком порядке, то b может завершиться раньше, чем a. Но приятная особенность gather заключается в том, что независимо от порядка завершения, результаты гарантировано будут возвращены в том порядке, в каком объекты передавались.

**Функция gather гарантирует детерминированный порядок результатов, несмотря на недетерменированность их получения**.


### Обработка исключений при использовании gather

asyncio.gather принимает необязательный параметр return_exceptions:
* return_exceptions = False - режим по умолчанию. Если хотя бы одно из сопрограмм возбуждает исключение, то gather тоже возбуждает исключение в точке await. Если ошибка будет обработана, то она не приведёт к остановке цикла событий и снятию задач.
* return_exceptions = True - исключения возвращаются в том же списке, что и результаты.

asyncio.gather() не снимает другие работающие задачи из-за отказа. Во многих случаях это приемлемо, но вообще является одним из недостатков gather.

Пример
```python
# Обработка исключений в asyncio.gather
import asyncio
import aiohttp
from aiohttp import ClientSession
from utils import async_timed


async def fetch_status(session: ClientSession, url: str) -> int:
	async with session.get(url) as result:
		return result.status


@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:
		urls = ['https://www.example.com', 'python://ru']
		requests = [fetch_status(session, url) for url in urls]
		
		# По дефолту False. Возбудит исключение, но другие задачи продолжат работу (в случае, если исключение обработается)
		# status_codes = await asyncio.gather(*requests, return_exceptions=False)

		# Не возбудит исключение, а просто вернёт его
		results = await asyncio.gather(*requests, return_exceptions=True)
		
		print('Ошибки', [res for res in results if isinstance(res, Exception)])
		print(
			'Успех', 
			[res for res in results if not isinstance(res, Exception)]
		)

asyncio.run(main())
```

Функция gather имеет несколько недостатков:
1. Не так просто отменить задачи,если одна из них возбудила исключение
2. Необходимость дождаться завершения всех сопрограмм, прежде чем  можно будет приступить к обработке результатов.


## Обработка результатов по мере поступления as_completed

Во многих случаях asyncio.gather нас устраивает,у  неё есть недостаток - необходимость дождаться завершения всех допускающих ожидания объектов, прежде чем станет возможен доступ к результатам.

Для решения этой проблемы asyncio предлагает функцию as_completed. Она принимает список допускающих ожидания объектов и возвращает итератор по ним. Эти объекты можно перебирать, применяя к ним await. Когда await вернёт управление - мы получим результат первой завершившейся сопрограммы. Следовательно мы сможем обрабатывать результаты по мере их доступности, но теперь порядок результатов недетерменирован, т.к. неизвестно, какая из задач завершится первой.

Пример
```python
# Использование as_completed
import asyncio
import aiohttp
from aiohttp import ClientSession
from utils import async_timed


async def fetch_status(
	session: ClientSession,
	url: str,
	delay: int = 0
) -> int:
	await asyncio.sleep(delay)
	async with session.get(url) as result:
		return result.status


@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:
		fetchers = [
			fetch_status(session, 'https://www.example.com', 1),
			fetch_status(session, 'https://www.example.com', 1),
			fetch_status(session, 'https://www.example.com', 10),
		]

  

		for finished_task in asyncio.as_completed(fetchers):
			print(await finished_task)

asyncio.run(main())
```


### Тайм-ауты в сочетании с as_completed

Любой веб-запрос может занять много времени. Возможно, сервер испытывает высокую нагрузку или сеть медленная.

Выше мы говорили о том, как задать тайм-аут, но функция as_completed предоставляет возможность задать параметр timeout. Если же во время выполнения потребуется больше времени, то каждый допускающий ожидания объект возбудит исключения TimeoutException в точке ожидания при помощи await.

Пример
```python
# Задание таймаута для as_completed
import asyncio
import aiohttp
from aiohttp import ClientSession
from utils import async_timed
  

async def fetch_status(
	session: ClientSession,
	url: str,
	delay: int = 0
) -> int:
	await asyncio.sleep(delay)
	async with session.get(url) as result:

		return result.status


@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:
		fetchers = [
			fetch_status(session, 'https://www.example.com', 1),
			fetch_status(session, 'https://www.example.com', 1),
			fetch_status(session, 'https://www.example.com', 10),
		]

  
		for done_task in asyncio.as_completed(fetchers, timeout=2):
			try:
				result = await done_task
				print(result)
			except asyncio.TimeoutError:
				print('Произошёл тайм-аут!')

		for task in asyncio.tasks.all_tasks():
			print(task)

asyncio.run(main())
```


Тут мы увидим результат первого вызова, а спустя 2 с два таймаута.

Недостатки:
1. Хотя мы и получаем результаты в темпе их поступления, но невозможно сказать, какую сопрограмму или задачу мы ждём. Порядок абсолютно недетерменирован.
2. Если какие-то задачи мы захотим снять, то будет непонятно, какие задачи ещё работают

## Точный контроль при помощи wait

Функция wati похожа на gather, но даёт более точный контроль над ситуацией. У неё есть несколько параметров, позволяющих решить, когда мы хотим получить результаты. 

Она возвращает два множества: задачи, завершившиеся успешно или в результате исключения, а также задачи, продолжающие выполняться.

Базовая сигнатура wait - список допускающих объектов, за которыми следует тайм-аут и параметр return_when, который принимает значения: ALL_COMPLETED (по умолчанию), FIRST_EXCEPTION, FIRST_COMPLETED


### Пример с ALL_COMPLETED (по умолчанию)
```python
# Изучение поведения wait по умолчанию
import asyncio
import aiohttp
from aiohttp import ClientSession
from utils import async_timed

  
async def fetch_status(
	session: ClientSession,
	url: str,
	delay: int = 0
) -> int:
	await asyncio.sleep(delay)
	async with session.get(url) as result:
		return result.status
  

@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:
		fetchers = [
			asyncio.create_task(fetch_status(session, 'https://example.com', 1)),
			asyncio.create_task(fetch_status(session, 'https://example.com', 1))
		]

		done, pending = await asyncio.wait(fetchers)

		print(f'Число завершившихся задач: {len(done)}')
		print(f'Число ожидающих задач: {len(pending)}')

		for done_task in done:
			result = await done_task
			print(result)

asyncio.run(main())
```


await wait вернёт управление, когда все запросы завершатся, и мы получим два множества: завершившиеся задачи (done) и ещё работающие задачи (pending).

В данном случае, так как используется параметр ALL_COMPLETED, pending будет пустым. (asyncio.wait не вернётся, пока не завершит все задачи).

**Примечание**
Если в одном из запросов возникает исключение, то wait не возбудит его, как gather.
В этом случае мы получаем оба множества, но не увидим исключения, **пока не применим await к той задаче из done, в котором было исключение.**

Пример с обработкой исключений
```python
# Обработка исключений при использовании wait
import asyncio
import logging
import aiohttp
from aiohttp import ClientSession
from utils import async_timed
  

async def fetch_status(
	session: ClientSession,
	url: str,
	delay: int = 0
) -> int:
	await asyncio.sleep(delay)
	async with session.get(url) as result:
		return result.status


@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:
		good_request = fetch_status(session, 'https://www.example.com')
		bad_request = fetch_status(session, 'python://bad')

		fetchers = [
			asyncio.create_task(good_request),
			asyncio.create_task(bad_request)
		]

		done, pending = await asyncio.wait(fetchers)

		print(f'Число завершившихся задач: {len(done)}')
		print(f'Число ожидающих задач: {len(pending)}')

		for done_task in done:
			# result = await done task возбудит исключение
			if done_task.exception() is None:
				print(done_task.result())
			else:
				logging.error(
					"При выполнении запроса возникло исключение",
					 exc_info=done_task.exception()
				)

asyncio.run(main())
```

**Функция done_task.exception() проверяет, имеет ли место исключение.**

ALL_COMPLETED обладает всеми теми же недостатками, что и gather.

### Пример с FIRST_EXCEPTION

**Если ни в одной задаче не возникло исключения, то этот метод эквивалентен ALL_COMPLETED**

Если хотя бы в одной задаче возникло исключение, то wait немедленно возвращается. Множество done будет содержать как задачи, которые завершились успешно, так и задачи, в которых имеет место исключение.

Пример
```python
import aiohttp
from aiohttp import ClientSession
import asyncio
import logging
from utils import async_timed

async def fetch_status(
	session: ClientSession,
	url: str,
	delay: int = 0
) -> int:
	await asyncio.sleep(delay)
	async with session.get(url) as result:
		return result.status

@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:

		fetchers = [
			asyncio.create_task(fetch_status(session, 'python://bad/com')),
			asyncio.create_task(fetch_status(
				session, 'https://www.example.com', delay=3)
			),
			asyncio.create_task(fetch_status(
				session, 'https://www.example.com', delay=3)
			)
		]

		done, pending = await asyncio.wait(
			fetchers, return_when=asyncio.FIRST_EXCEPTION
		)
		# 1 задача, которая завершилась с ошибкой
		print(f'Число завершившихся задач: {len(done)}')
		# 2 ожидающий задачи
		print(f'Число ожидающих задач: {len(pending)}')

		for done_task in done:
			if done_task.exception() is None:
				print(done_task.result())
			else:
				logging.error(
					'При выполнении запроса возникло исключение', 
					exc_info=done_task.exception()
				)

		for pending_task in pending:
			pending_task.cancel()

asyncio.run(main())
```


### Пример с FIRST_COMPLETED

В этом случае возвращает управление как только получен хотя бы один результат. Это может быть как успешно завершившаяся задача, так и задача, в которой возникло исключение. Остальные задачи можно либо снять, либо дать им продолжить работу

Пример
```python
# Обработка запросов по мере завершения
import asyncio
import aiohttp
from utils import async_timed
from aiohttp import ClientSession


async def fetch_status(
	session: ClientSession,
	url: str,
	delay: int = 0
) -> int:
	await asyncio.sleep(delay)

	async with session.get(url) as result:
		return result.status
  

@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:
		url = 'https://www.example.com'

		fetchers = [
			asyncio.create_task(fetch_status(session, url)),
			asyncio.create_task(fetch_status(session, url)),
			asyncio.create_task(fetch_status(session, url))
		]

		done, pending = await asyncio.wait(
			fetchers,
			return_when=asyncio.FIRST_COMPLETED
		)

		print(f'Число завершившихся задач: {len(done)}')	
		print(f'Число ожидающих задач: {len(pending)}')

		for done_task in done:
			print(await done_task)

asyncio.run(main())
```

Описанный подход позволяет реагировать тогда, когда завершится задача. Но если мы хотим, чтобы и остальные результаты обработались, то можно применить следующий подход

```python
# Обработка всех результатов по мере завершения
import asyncio
import aiohttp
from utils import async_timed
from aiohttp import ClientSession
  

async def fetch_status(
	session: ClientSession,
	url: str,
	delay: int = 0
) -> int:
	await asyncio.sleep(delay)
	async with session.get(url) as result:
		return result.status


@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:
		url = 'https://www.example.com'

		pending = [
			asyncio.create_task(fetch_status(session, url)),
			asyncio.create_task(fetch_status(session, url)),
			asyncio.create_task(fetch_status(session, url))
		]
		# Выполняется, пока в pending есть элементы
		while pending:
			done, pending = await asyncio.wait(
				pending,
				return_when=asyncio.FIRST_COMPLETED
			)

			print(f'Число завершившихся задач: {len(done)}')
			print(f'Число ожидающих задач: {len(pending)}')

			for done_task in done:
				print(await done_task)

asyncio.run(main())
```


### Обработка тайм-аутов в wait

Для тайм-аута следует также задать параметр timeout, указав в нём максимальное время работы в секундах. Есть два отличия от as_completed:
1. Сопрограммы не снимаются автоматически. Чтобы снять их нужно явно обойти их и снять каждую из них
2. Исключения не возбуждаются. wait возвращает все завершившиеся задачи, а также те, что ещё не завершились в момент тайм-аута.

Пример
```python
# Использование тайм-аутов в wait
import asyncio
import aiohttp
from utils import async_timed
from aiohttp import ClientSession


async def fetch_status(
	session: ClientSession,
	url: str,
	delay: int = 0
) -> int:
	await asyncio.sleep(delay)

	async with session.get(url) as result:
		return result.status


@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:
		url = 'https://example.com'
		fetchers = [
			asyncio.create_task(fetch_status(session, url)),
			asyncio.create_task(fetch_status(session, url)),
			asyncio.create_task(fetch_status(session, url, delay=3)),
		]

		done, pending = await asyncio.wait(fetchers, timeout=1)

		print(f'Число завершившихся задач: {len(done)}')
		print(f'Число ожидающих задач: {len(pending)}')

		for done_task in done:
			result = await done_task
			print(result)


asyncio.run(main())
```


### Зачем оборачивать сопрограммы задачами?

Вернёмся к предыдущему примеру. Пусть имеется два запроса к разным API (API A и API B). Оба могут тормозить, но наше приложение может продолжить работу, не получив результат от API B, просто было бы хорошо его иметь. Мы хотим, чтобы приложение было отзывчивым, поэтому задаём для запросов тайм-аут 1 с. Если тайм-аут истёк, а запрос всё ещё работает, то мы отменяем его. В случае если не обёртывать соопрограмму  задачами, то в мы не увидим фразу 'API B слишком медленный'
```python
# Использование тайм-аутов в wait
import asyncio
import aiohttp
from utils import async_timed
from aiohttp import ClientSession

async def fetch_status(
	session: ClientSession,
	url: str,
	delay: int = 0
) -> int:
	await asyncio.sleep(delay)

	async with session.get(url) as result:
		return result.status


@async_timed()
async def main():
	async with aiohttp.ClientSession() as session:
		url = 'https://example.com'

		api_a = fetch_status(session, url)
		api_b = fetch_status(session, url)

		done, pending = await asyncio.wait([api_a, api_b], timeout=1)

		for task in pending:
			if task is api_b:
				print('API B слишком медленный, отмена')
				task.cancel()

asyncio.run(main())
```

Так происходит потому, что в wait передаются две сопрограммы, они автоматически обёртываются задачами, а возвращённые множества будут содержать эти задачи. Следовательно неправильно будет проверять pending на присутствие задачи, ибо мы сравниваем сопрограмму и задачу.


## Резюме

* Асинхронные контекстные менеджеры - это специальные классы, которые позволяют захватывать ресурсы, а затем освобождать их даже при наличии исключения. Их задача - очистить захваченные ресурсы без лишнего кода. Для них есть специальная конструкция - async with
* Для отправки асинх. запросов и для создангия сервера с неблокирующими сокетами используется библиотека aiohttp
* asyncio.gather позволяет конкурентно запустить несколько сопрограмм и ждать их завершения. Она возвращает управление, когда все объекты завершают свою работу. Для отслеживания исключений используется return_exception=True (по дефолту False). Исключения вернутся в том же списке, что и результаты. В случае False все задачи будут сняты (если исключение не обработано).
* asyncio.as_completed - позволяет обрабатывать результаты по мере их завершения. Она возвращает итератор по будущим объектам, который можно обойти в цикле
* asycnio.wait - предоставляет более гибкий подход к обработке задач. Она даёт более точный контроль над моментом возврата результатов. После возврата мы получаем множество завершившихся задач и множество ещё работающих.